{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13581807,"sourceType":"datasetVersion","datasetId":8565895}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":51.1855,"end_time":"2025-10-27T06:12:49.761868","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-27T06:11:58.576368","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"01270a0002324330a11158f8295ac440":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"023be933040a458da0319a8d9fb3895f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06e870cc59d94244890b1c0bb4ee8984":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","button_color":null,"font_family":null,"font_size":null,"font_style":null,"font_variant":null,"font_weight":null,"text_color":null,"text_decoration":null}},"0e074d701e814a378c88982d0e0cb97e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_aab02db3981b4ccb83afc8422ee09034","placeholder":"​","style":"IPY_MODEL_458f117b0c3b43f1814105f1d97a102e","tabbable":null,"tooltip":null,"value":"<b>Active dataset label:</b> not set"}},"10ec038ccc84497894b4a8b9ec72c887":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_2ea71721b5f549b9996ff1c7a86b6eb6","IPY_MODEL_0e074d701e814a378c88982d0e0cb97e"],"layout":"IPY_MODEL_7dc6f6096f6743c9b24d4940218abdbc","tabbable":null,"tooltip":null}},"162ceafed8584db68653a41c639a0175":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_eba4bbdb70b540a3be40bb97e0155b83","placeholder":"​","style":"IPY_MODEL_76eb42d2966b40d4936876d2258d5251","tabbable":null,"tooltip":null,"value":"performance_dense epochs:  20%"}},"1a18e9638ded455b88f781c205dab385":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1dee667a37f04b7fa1aba6ff1bbe2fb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fd4f83c003344afb73e9afd7738f5fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"2472bf23e2cd49439ec928a49330b08f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"298c139b92c04423b91a11e74a2f84d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"TextView","continuous_update":true,"description":"momentum_policy_rl — 20251027-061222","description_allow_html":false,"disabled":false,"layout":"IPY_MODEL_91a13666628a44ab98d2edd91abfbf65","placeholder":"Enter dataset name","style":"IPY_MODEL_b70eb7c3e85347f7a975e9d17d7b4172","tabbable":null,"tooltip":null,"value":""}},"2cb5658fa2b445fabb31bd57b0df863a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de038521e27c40a98d4dc2d7cbadbf4b","IPY_MODEL_8cb4bdc8fefa45a687f54593d95ebabe","IPY_MODEL_cde21250fa5e43d2a558551555866092"],"layout":"IPY_MODEL_8dcbfa20cb634226b73fd9a789da6219","tabbable":null,"tooltip":null}},"2ea71721b5f549b9996ff1c7a86b6eb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"TextView","continuous_update":true,"description":"Dataset:","description_allow_html":false,"disabled":false,"layout":"IPY_MODEL_edfc4c0610f7437294335a187af21e9e","placeholder":"e.g., Kaggle Dataset v1","style":"IPY_MODEL_45f6fd15d02a46dead4fe394c07aaf73","tabbable":null,"tooltip":null,"value":""}},"331e323a8d6445c199012873dc8ac4c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3e920957201482483bfc5d081a39fbc","IPY_MODEL_4575568df0f34516909a60572e380eb9","IPY_MODEL_c6c759831fd143bd94065572ea6727c8"],"layout":"IPY_MODEL_847009839b3643d2806a7afabd112211","tabbable":null,"tooltip":null}},"4575568df0f34516909a60572e380eb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_940dbb343599471d9f23affd700646c7","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a18e9638ded455b88f781c205dab385","tabbable":null,"tooltip":null,"value":3}},"458f117b0c3b43f1814105f1d97a102e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"45f6fd15d02a46dead4fe394c07aaf73":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"4b4f08dade2f41e78d5353437e7e5df6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2472bf23e2cd49439ec928a49330b08f","placeholder":"​","style":"IPY_MODEL_e2cc2ecf1dd84fafaed3162a822c3451","tabbable":null,"tooltip":null,"value":""}},"5bbfc9a79a4c487a8e20b0bc9febca99":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b25a9cd4576e43f8b772c1f7f2d21bc7","IPY_MODEL_298c139b92c04423b91a11e74a2f84d3","IPY_MODEL_d4d8b34b907e4705aefe8d0092b73eca","IPY_MODEL_9d42a4465b0145999e126bb2c67b1bb6","IPY_MODEL_4b4f08dade2f41e78d5353437e7e5df6"],"layout":"IPY_MODEL_b4d9d7218cfb4d55a9cc0f3ba4ac098e","tabbable":null,"tooltip":null}},"5c27b99c5e53400ebec41c9e9d90f3ca":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dc4d3a734c645979c1add7b2b0a7152":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"70%"}},"76eb42d2966b40d4936876d2258d5251":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"77976649da1f4d24853a3d7d4a3b4dae":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_023be933040a458da0319a8d9fb3895f","placeholder":"​","style":"IPY_MODEL_ac0a7dcaee904632a6128f17ed698566","tabbable":null,"tooltip":null,"value":" 10/50 [00:03&lt;00:07,  5.30it/s, val_acc=0.408, loss=1.104]"}},"7dc6f6096f6743c9b24d4940218abdbc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81e27fa55e2d4e7591dbe419603070dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"847009839b3643d2806a7afabd112211":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"8b1ab04d6f3041a49ffedb50b60c68ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8cb4bdc8fefa45a687f54593d95ebabe":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"","description":"","description_allow_html":false,"layout":"IPY_MODEL_5c27b99c5e53400ebec41c9e9d90f3ca","max":60,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dee667a37f04b7fa1aba6ff1bbe2fb1","tabbable":null,"tooltip":null,"value":60}},"8dcbfa20cb634226b73fd9a789da6219":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"91a13666628a44ab98d2edd91abfbf65":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"70%"}},"940dbb343599471d9f23affd700646c7":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95d6c5b744104f7ab5643dfe55c4f547":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_allow_html":false,"layout":"IPY_MODEL_9705548b9d8d4336b88bfcb4c21d6fdc","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_81e27fa55e2d4e7591dbe419603070dc","tabbable":null,"tooltip":null,"value":10}},"9705548b9d8d4336b88bfcb4c21d6fdc":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d42a4465b0145999e126bb2c67b1bb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ButtonView","button_style":"primary","description":"Apply labels","disabled":false,"icon":"","layout":"IPY_MODEL_f1a9dec992eb4a30ba1d998afc905333","style":"IPY_MODEL_06e870cc59d94244890b1c0bb4ee8984","tabbable":null,"tooltip":null}},"9f8d27324ba344208d118d9c6025a8c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_162ceafed8584db68653a41c639a0175","IPY_MODEL_95d6c5b744104f7ab5643dfe55c4f547","IPY_MODEL_77976649da1f4d24853a3d7d4a3b4dae"],"layout":"IPY_MODEL_af937d7b54d84daea3251b0873079526","tabbable":null,"tooltip":null}},"aab02db3981b4ccb83afc8422ee09034":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac0a7dcaee904632a6128f17ed698566":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"acfdc61a0aff4acda3b6d95a07c48767":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af937d7b54d84daea3251b0873079526":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b25a9cd4576e43f8b772c1f7f2d21bc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"TextView","continuous_update":true,"description":"performance_dense — 20251027-061222","description_allow_html":false,"disabled":false,"layout":"IPY_MODEL_5dc4d3a734c645979c1add7b2b0a7152","placeholder":"Enter dataset name","style":"IPY_MODEL_e68b5c98e8064f6d985033964aa0db6b","tabbable":null,"tooltip":null,"value":""}},"b4d9d7218cfb4d55a9cc0f3ba4ac098e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b70eb7c3e85347f7a975e9d17d7b4172":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"bc31c2103f4440c883226112696ad15a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6c759831fd143bd94065572ea6727c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e1ceab3e9fe04013af5968d54019af1c","placeholder":"​","style":"IPY_MODEL_01270a0002324330a11158f8295ac440","tabbable":null,"tooltip":null,"value":" 3/3 [00:22&lt;00:00,  6.86s/it]"}},"c91795e9dce74bdc9a6ba10595a23c72":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cde21250fa5e43d2a558551555866092":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_bc31c2103f4440c883226112696ad15a","placeholder":"​","style":"IPY_MODEL_1fd4f83c003344afb73e9afd7738f5fe","tabbable":null,"tooltip":null,"value":" 60/60 [00:17&lt;00:00,  3.58it/s, val_acc=0.504, loss=-0.028]"}},"d4d8b34b907e4705aefe8d0092b73eca":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"TextView","continuous_update":true,"description":"market_gradient_boost — 20251027-061222","description_allow_html":false,"disabled":false,"layout":"IPY_MODEL_da77df301b504ab5be264ff603dbe71c","placeholder":"Enter dataset name","style":"IPY_MODEL_fbfc2afc1d43480fa0d12670eabaf07f","tabbable":null,"tooltip":null,"value":""}},"da77df301b504ab5be264ff603dbe71c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"70%"}},"de038521e27c40a98d4dc2d7cbadbf4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_efcd9d334dc0408aa329cea7589aa406","placeholder":"​","style":"IPY_MODEL_8b1ab04d6f3041a49ffedb50b60c68ea","tabbable":null,"tooltip":null,"value":"momentum_policy_rl policy: 100%"}},"e1ceab3e9fe04013af5968d54019af1c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2cc2ecf1dd84fafaed3162a822c3451":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e68b5c98e8064f6d985033964aa0db6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"eba4bbdb70b540a3be40bb97e0155b83":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfc4c0610f7437294335a187af21e9e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"efcd9d334dc0408aa329cea7589aa406":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1a9dec992eb4a30ba1d998afc905333":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e920957201482483bfc5d081a39fbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_acfdc61a0aff4acda3b6d95a07c48767","placeholder":"​","style":"IPY_MODEL_c91795e9dce74bdc9a6ba10595a23c72","tabbable":null,"tooltip":null,"value":"Baselines: 100%"}},"fbfc2afc1d43480fa0d12670eabaf07f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"TextStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"TextStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/yovipi/football-predictor-model-ipynb?scriptVersionId=270368239\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{"papermill":{"duration":0.00576,"end_time":"2025-10-27T06:12:03.071179","exception":false,"start_time":"2025-10-27T06:12:03.065419","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"\n# The Beautiful Game Oracle — Baseline TensorFlow Suite\n\nThis notebook prepares and compares three TensorFlow/Keras baseline models for predicting English Premier League match outcomes using data pulled directly from the Understat API. It aligns with the project charter in `README.md` and the agent directives in `AGENTS.md`, emphasising reproducible experiments, attribution readiness, and run tracking for longitudinal comparisons.\n","metadata":{"papermill":{"duration":0.005783,"end_time":"2025-10-27T06:12:03.082961","exception":false,"start_time":"2025-10-27T06:12:03.077178","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"\n## Workflow Overview\n- Fetch and cache historical EPL match data from Understat for configurable seasons.\n- Engineer team form, momentum, and market-derived features compatible with TensorFlow pipelines.\n- Train three complementary baselines (performance-form dense net, momentum interaction network, forecast calibrator) and save artefacts for reuse.\n- Persist metrics and artefacts per run, append to a cumulative history log, and generate comparison visuals versus prior runs.\n- Prepare the infrastructure needed for downstream attribution work (Shapley/LOO) by keeping models and datasets aligned with saved run metadata.\n","metadata":{"papermill":{"duration":0.005733,"end_time":"2025-10-27T06:12:03.094792","exception":false,"start_time":"2025-10-27T06:12:03.089059","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Environment Setup","metadata":{"papermill":{"duration":0.005869,"end_time":"2025-10-27T06:12:03.106662","exception":false,"start_time":"2025-10-27T06:12:03.100793","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\nimport os\nimport json\nimport math\nimport time\nimport re\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport requests\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tqdm.auto import tqdm\nfrom tqdm.keras import TqdmCallback\nimport xgboost as xgb\nfrom IPython.display import display\nimport ipywidgets as widgets\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-v0_8')\npd.options.display.max_columns = 100\n\nSEED = 42\nnp.random.seed(SEED)\ntf.keras.utils.set_random_seed(SEED)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:16:49.687400Z","iopub.execute_input":"2025-11-20T05:16:49.688420Z","iopub.status.idle":"2025-11-20T05:16:49.696691Z","shell.execute_reply.started":"2025-11-20T05:16:49.688383Z","shell.execute_reply":"2025-11-20T05:16:49.695325Z"},"papermill":{"duration":19.627098,"end_time":"2025-10-27T06:12:22.739848","exception":false,"start_time":"2025-10-27T06:12:03.11275","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## Experiment Configuration","metadata":{"papermill":{"duration":0.005922,"end_time":"2025-10-27T06:12:22.752566","exception":false,"start_time":"2025-10-27T06:12:22.746644","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Experiment configuration\nPROJECT_NAME = \"The-Beautiful-Game-Oracle\"\nLEAGUE = \"EPL\"\nSEASONS = [\"2023\", \"2022\", \"2021\", \"2020\"]  # extend or adjust as needed\nROLLING_WINDOW = 5\nBATCH_SIZE = 64\nEPOCHS = 50\nREFRESH_DATA = False  # set True to refetch from Understat\nRUN_ID = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\nDATASET_LABEL = None\n\n# Filesystem locations (compatible with Kaggle + local use)\nLEAGUE_RESULTS_PATH: Path | None = None\n\nif Path(\"/kaggle\").exists():\n    BASE_WORKING_DIR = Path(\"/kaggle/working\")\n    candidate_paths = [\n        Path(\"/kaggle/input/football-predictor-dataset/Dataset_Version_3.csv\"),\n        Path(\"/kaggle/input/football-predictor-dataset/Dataset.csv\"),\n    ]\nelse:\n    BASE_WORKING_DIR = Path(\"./artifacts\")\n    candidate_paths = [\n        Path(\"understat_data/Dataset_Version_3.csv\"),\n        Path(\"understat_data/Dataset.csv\"),\n        Path(\"understat_data/league_results_v2.csv\"),\n    ]\n\nfor candidate in candidate_paths:\n    if candidate.exists():\n        LEAGUE_RESULTS_PATH = candidate\n        break\n\nif LEAGUE_RESULTS_PATH is None or not LEAGUE_RESULTS_PATH.exists():\n    raise FileNotFoundError(f\"League results CSV missing at any of: {candidate_paths}\")\n\nEXPERIMENT_ROOT = BASE_WORKING_DIR / \"experiments\"\nCACHE_DIR = EXPERIMENT_ROOT / \"understat_cache\"\nMODEL_ARTIFACT_DIR = EXPERIMENT_ROOT / f\"run_{RUN_ID}\"\nRUN_LOG_PATH = EXPERIMENT_ROOT / \"baseline_run_history.csv\"\n\nfor path in [EXPERIMENT_ROOT, CACHE_DIR, MODEL_ARTIFACT_DIR]:\n    path.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Project: {PROJECT_NAME}\")\nprint(f\"Seasons loaded: {SEASONS}\")\nprint(f\"Working dir: {BASE_WORKING_DIR.resolve()}\")\nprint(f\"League results source: {LEAGUE_RESULTS_PATH}\")\nprint(f\"Current run artefacts: {MODEL_ARTIFACT_DIR}\")\nRUN_LOG_COLUMNS = [\n    \"timestamp\",\n    \"run_id\",\n    \"baseline\",\n    \"trainer\",\n    \"feature_view\",\n    \"train_accuracy\",\n    \"val_accuracy\",\n    \"test_accuracy\",\n    \"train_loss\",\n    \"val_loss\",\n    \"test_loss\",\n    \"val_logloss\",\n    \"test_logloss\",\n    \"epochs_trained\",\n    \"seasons\",\n    \"dataset_label\",\n    \"notes\",\n]\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:21.372512Z","iopub.execute_input":"2025-11-20T05:17:21.372856Z","iopub.status.idle":"2025-11-20T05:17:21.387756Z","shell.execute_reply.started":"2025-11-20T05:17:21.372834Z","shell.execute_reply":"2025-11-20T05:17:21.386423Z"},"papermill":{"duration":0.024917,"end_time":"2025-10-27T06:12:22.791692","exception":false,"start_time":"2025-10-27T06:12:22.766775","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Project: The-Beautiful-Game-Oracle\nSeasons loaded: ['2023', '2022', '2021', '2020']\nWorking dir: /kaggle/working\nLeague results source: /kaggle/input/football-predictor-dataset/Dataset_Version_3.csv\nCurrent run artefacts: /kaggle/working/experiments/run_20251120-051721\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"### Dataset Label Input\nUse the box below to assign a dataset label for this run. This label will be stored with training logs and shown in historical comparisons.","metadata":{"papermill":{"duration":0.013181,"end_time":"2025-10-27T06:12:22.812774","exception":false,"start_time":"2025-10-27T06:12:22.799593","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Interactive dataset label capture\ndataset_label_box = widgets.Text(\n    value=DATASET_LABEL or \"\",\n    placeholder=\"e.g., Kaggle Dataset v1\",\n    description=\"Dataset:\",\n    layout=widgets.Layout(width=\"50%\"),\n)\n\ndataset_label_status = widgets.HTML()\n\ndef _update_dataset_label(change=None):\n    global DATASET_LABEL\n    label = dataset_label_box.value.strip()\n    DATASET_LABEL = label if label else None\n    display_value = DATASET_LABEL or \"not set\"\n    dataset_label_status.value = f\"<b>Active dataset label:</b> {display_value}\"\n\n_update_dataset_label()\ndataset_label_box.observe(_update_dataset_label, names=\"value\")\ndisplay(widgets.VBox([dataset_label_box, dataset_label_status]))\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:34.650681Z","iopub.execute_input":"2025-11-20T05:17:34.651074Z","iopub.status.idle":"2025-11-20T05:17:34.667450Z","shell.execute_reply.started":"2025-11-20T05:17:34.651039Z","shell.execute_reply":"2025-11-20T05:17:34.666015Z"},"papermill":{"duration":0.043797,"end_time":"2025-10-27T06:12:22.871567","exception":false,"start_time":"2025-10-27T06:12:22.82777","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Text(value='V3', description='Dataset:', layout=Layout(width='50%'), placeholder='e.g., Kaggle …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500c34c18f9c4a73a048decfd3b38e93"}},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"## Data Acquisition","metadata":{"papermill":{"duration":0.012387,"end_time":"2025-10-27T06:12:22.897961","exception":false,"start_time":"2025-10-27T06:12:22.885574","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n# Understat data retrieval helpers\n\"\"\"\nHEADERS = {\n    \"User-Agent\": \"Mozilla/5.0 (compatible; The-Beautiful-Game-Oracle/1.0)\",\n}\n\nMATCHES_PATTERN = re.compile(r\"var\\s+datesData\\s*=\\s*JSON.parse\\('(.+?)'\\)\")\n\n\ndef fetch_understat_dates(league: str, season: str, *, refresh: bool = False) -> list:\n    '''Download Understat league matches for a season, with on-disk caching.'''\n    cache_path = CACHE_DIR / f\"{league}_{season}_dates.json\"\n    if cache_path.exists() and not refresh:\n        try:\n            return json.loads(cache_path.read_text())\n        except json.JSONDecodeError:\n            pass  # fall back to refetching\n\n    url = f\"https://understat.com/league/{league}/{season}\"\n    response = requests.get(url, headers=HEADERS, timeout=30)\n    response.raise_for_status()\n    match = MATCHES_PATTERN.search(response.text)\n    if not match:\n        raise RuntimeError(f\"datesData block not found for {league} {season}\")\n    decoded = match.group(1).encode(\"utf-8\").decode(\"unicode_escape\")\n    data = json.loads(decoded)\n    cache_path.write_text(json.dumps(data))\n    time.sleep(0.5)  # be gentle with the source\n    return data\n\n\ndef load_matches_for_seasons(league: str, seasons: list[str], refresh: bool = False) -> dict[str, list]:\n    payload = {}\n    for season in seasons:\n        payload[season] = fetch_understat_dates(league, season, refresh=refresh)\n        print(f\"Loaded {len(payload[season])} fixtures for {league} {season}\")\n    return payload\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:41.707034Z","iopub.execute_input":"2025-11-20T05:17:41.707395Z","iopub.status.idle":"2025-11-20T05:17:41.716169Z","shell.execute_reply.started":"2025-11-20T05:17:41.707359Z","shell.execute_reply":"2025-11-20T05:17:41.714830Z"},"papermill":{"duration":0.017123,"end_time":"2025-10-27T06:12:22.924865","exception":false,"start_time":"2025-10-27T06:12:22.907742","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"'\\nHEADERS = {\\n    \"User-Agent\": \"Mozilla/5.0 (compatible; The-Beautiful-Game-Oracle/1.0)\",\\n}\\n\\nMATCHES_PATTERN = re.compile(r\"var\\\\s+datesData\\\\s*=\\\\s*JSON.parse\\\\(\\'(.+?)\\'\\\\)\")\\n\\n\\ndef fetch_understat_dates(league: str, season: str, *, refresh: bool = False) -> list:\\n    \\'\\'\\'Download Understat league matches for a season, with on-disk caching.\\'\\'\\'\\n    cache_path = CACHE_DIR / f\"{league}_{season}_dates.json\"\\n    if cache_path.exists() and not refresh:\\n        try:\\n            return json.loads(cache_path.read_text())\\n        except json.JSONDecodeError:\\n            pass  # fall back to refetching\\n\\n    url = f\"https://understat.com/league/{league}/{season}\"\\n    response = requests.get(url, headers=HEADERS, timeout=30)\\n    response.raise_for_status()\\n    match = MATCHES_PATTERN.search(response.text)\\n    if not match:\\n        raise RuntimeError(f\"datesData block not found for {league} {season}\")\\n    decoded = match.group(1).encode(\"utf-8\").decode(\"unicode_escape\")\\n    data = json.loads(decoded)\\n    cache_path.write_text(json.dumps(data))\\n    time.sleep(0.5)  # be gentle with the source\\n    return data\\n\\n\\ndef load_matches_for_seasons(league: str, seasons: list[str], refresh: bool = False) -> dict[str, list]:\\n    payload = {}\\n    for season in seasons:\\n        payload[season] = fetch_understat_dates(league, season, refresh=refresh)\\n        print(f\"Loaded {len(payload[season])} fixtures for {league} {season}\")\\n    return payload\\n'"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"## Feature Engineering Utilities","metadata":{"papermill":{"duration":0.006133,"end_time":"2025-10-27T06:12:22.937674","exception":false,"start_time":"2025-10-27T06:12:22.931541","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n# Feature engineering utilities\nfrom typing import Dict, List, Tuple\n\nCLASS_LABELS = [\"Home Win\", \"Draw\", \"Away Win\"]\n\n\ndef resolve_outcome_target(df: pd.DataFrame) -> pd.Series:\n    \"\"\"Map dataset outcome signals to canonical CLASS_LABELS ordering.\"\"\"\n    label_to_index = {label: idx for idx, label in enumerate(CLASS_LABELS)}\n    if \"outcome_id\" in df.columns:\n        outcome_series = pd.to_numeric(df[\"outcome_id\"], errors=\"coerce\")\n        if \"match_outcome\" in df.columns:\n            crosswalk = (\n                pd.DataFrame({\n                    \"outcome_id\": outcome_series,\n                    \"match_outcome\": df[\"match_outcome\"],\n                })\n                .dropna()\n                .drop_duplicates()\n            )\n            if not crosswalk.empty:\n                id_to_label = {\n                    int(row.outcome_id): row.match_outcome\n                    for row in crosswalk.itertuples(index=False)\n                    if row.match_outcome in label_to_index\n                }\n                if id_to_label:\n                    remap = {oid: label_to_index[label] for oid, label in id_to_label.items()}\n                    mapped = outcome_series.map(remap)\n                    if mapped.notna().all():\n                        return mapped.astype(int)\n        canonical_map = {0: label_to_index[\"Home Win\"], 1: label_to_index[\"Draw\"], 2: label_to_index[\"Away Win\"]}\n        mapped = outcome_series.map(canonical_map)\n        if mapped.notna().all():\n            return mapped.astype(int)\n    if \"match_outcome_code\" in df.columns:\n        code_map = {\n            \"H\": label_to_index[\"Home Win\"],\n            \"D\": label_to_index[\"Draw\"],\n            \"A\": label_to_index[\"Away Win\"],\n        }\n        return df[\"match_outcome_code\"].map(code_map).astype(int)\n    if \"match_outcome\" in df.columns:\n        return df[\"match_outcome\"].map(label_to_index).astype(int)\n    raise KeyError(\"Could not resolve outcome target columns for dataset.\")\n\n\n\ndef build_match_dataframe(matches_by_season: Dict[str, List[dict]]) -> pd.DataFrame:\n    rows = []\n    for season, matches in matches_by_season.items():\n        for match in matches:\n            if not match.get(\"isResult\"):\n                continue  # skip fixtures without a final result\n            rows.append({\n                \"match_id\": int(match[\"id\"]),\n                \"season\": season,\n                \"match_date\": pd.to_datetime(match[\"datetime\"], format=\"%Y-%m-%d %H:%M:%S\"),\n                \"home_team\": match[\"h\"][\"title\"],\n                \"away_team\": match[\"a\"][\"title\"],\n                \"home_goals\": int(match[\"goals\"][\"h\"]),\n                \"away_goals\": int(match[\"goals\"][\"a\"]),\n                \"home_xg\": float(match[\"xG\"][\"h\"]),\n                \"away_xg\": float(match[\"xG\"][\"a\"]),\n                \"home_prob_win\": float(match[\"forecast\"][\"w\"]),\n                \"draw_prob\": float(match[\"forecast\"][\"d\"]),\n                \"away_prob_win\": float(match[\"forecast\"][\"l\"]),\n            })\n    frame = pd.DataFrame(rows).sort_values(\"match_date\").reset_index(drop=True)\n    print(f\"Prepared {len(frame)} completed fixtures across seasons {sorted(matches_by_season.keys())}\")\n    return frame\n\n\ndef build_team_match_rows(match_df: pd.DataFrame) -> pd.DataFrame:\n    rows = []\n    for row in match_df.itertuples(index=False):\n        rows.append({\n            \"match_id\": row.match_id,\n            \"season\": row.season,\n            \"match_date\": row.match_date,\n            \"team\": row.home_team,\n            \"opponent\": row.away_team,\n            \"is_home\": 1,\n            \"goals_for\": row.home_goals,\n            \"goals_against\": row.away_goals,\n            \"xg_for\": row.home_xg,\n            \"xg_against\": row.away_xg,\n            \"prob_win\": row.home_prob_win,\n            \"prob_loss\": row.away_prob_win,\n            \"draw_prob\": row.draw_prob,\n        })\n        rows.append({\n            \"match_id\": row.match_id,\n            \"season\": row.season,\n            \"match_date\": row.match_date,\n            \"team\": row.away_team,\n            \"opponent\": row.home_team,\n            \"is_home\": 0,\n            \"goals_for\": row.away_goals,\n            \"goals_against\": row.home_goals,\n            \"xg_for\": row.away_xg,\n            \"xg_against\": row.home_xg,\n            \"prob_win\": row.away_prob_win,\n            \"prob_loss\": row.home_prob_win,\n            \"draw_prob\": row.draw_prob,\n        })\n    team_df = pd.DataFrame(rows).sort_values(\"match_date\").reset_index(drop=True)\n    team_df[\"goal_diff\"] = team_df[\"goals_for\"] - team_df[\"goals_against\"]\n    team_df[\"xg_diff\"] = team_df[\"xg_for\"] - team_df[\"xg_against\"]\n    return team_df\n\n\ndef add_form_features(team_df: pd.DataFrame, window: int = 5) -> pd.DataFrame:\n    feature_cols = [\n        \"goals_for\",\n        \"goals_against\",\n        \"goal_diff\",\n        \"xg_for\",\n        \"xg_against\",\n        \"xg_diff\",\n        \"prob_win\",\n    ]\n\n    def enrich(group: pd.DataFrame) -> pd.DataFrame:\n        g = group.copy()\n        for col in feature_cols:\n            shifted = g[col].shift(1)\n            g[f\"form_{col}_mean\"] = shifted.rolling(window, min_periods=1).mean().fillna(0)\n            g[f\"form_{col}_std\"] = shifted.rolling(window, min_periods=1).std().fillna(0)\n            g[f\"form_{col}_last\"] = shifted.fillna(0)\n        return g\n\n    enriched = (\n        team_df.sort_values(\"match_date\")\n        .groupby(\"team\", group_keys=False)\n        .apply(enrich)\n        .reset_index(drop=True)\n    )\n    return enriched\n\n\ndef assemble_match_features(team_form_df: pd.DataFrame) -> pd.DataFrame:\n    keep_cols = [\"match_id\", \"season\", \"match_date\", \"home_team\", \"away_team\"]\n\n    home = team_form_df[team_form_df[\"is_home\"] == 1].copy()\n    away = team_form_df[team_form_df[\"is_home\"] == 0].copy()\n\n    home.rename(columns={\"team\": \"home_team\", \"opponent\": \"away_team\"}, inplace=True)\n    away.rename(columns={\"team\": \"away_team\", \"opponent\": \"home_team\"}, inplace=True)\n\n    def prefix_except(df: pd.DataFrame, prefix: str, exclude: List[str]) -> pd.DataFrame:\n        rename_map = {col: f\"{prefix}{col}\" for col in df.columns if col not in exclude}\n        return df.rename(columns=rename_map)\n\n    home_prefixed = prefix_except(home, \"home_\", keep_cols)\n    away_prefixed = prefix_except(away, \"away_\", keep_cols)\n\n    merged = home_prefixed.merge(\n        away_prefixed,\n        on=[\"match_id\", \"season\", \"match_date\", \"home_team\", \"away_team\"],\n        how=\"inner\",\n        suffixes=(\"\", \"_dup\"),\n    )\n\n    if \"home_draw_prob\" in merged.columns:\n        merged.rename(columns={\"home_draw_prob\": \"match_draw_prob\"}, inplace=True)\n    if \"away_draw_prob\" in merged.columns:\n        merged.drop(columns=[\"away_draw_prob\"], inplace=True)\n\n    merged[\"target\"] = np.select(\n        [\n            merged[\"home_goals_for\"] > merged[\"away_goals_for\"],\n            merged[\"home_goals_for\"] == merged[\"away_goals_for\"],\n        ],\n        [0, 1],\n        default=2,\n    )\n\n    merged.sort_values(\"match_date\", inplace=True)\n    merged.reset_index(drop=True, inplace=True)\n    return merged\n\n\ndef build_feature_deltas(match_df: pd.DataFrame) -> pd.DataFrame:\n    df = match_df.copy()\n    df[\"form_goal_diff_delta\"] = df[\"home_form_goal_diff_mean\"] - df[\"away_form_goal_diff_mean\"]\n    df[\"form_xg_diff_delta\"] = df[\"home_form_xg_diff_mean\"] - df[\"away_form_xg_diff_mean\"]\n    df[\"form_prob_win_delta\"] = df[\"home_form_prob_win_mean\"] - df[\"away_form_prob_win_mean\"]\n    df[\"form_goal_last_delta\"] = df[\"home_form_goal_diff_last\"] - df[\"away_form_goal_diff_last\"]\n    df[\"form_xg_last_delta\"] = df[\"home_form_xg_diff_last\"] - df[\"away_form_xg_diff_last\"]\n    df[\"prob_edge\"] = df[\"home_prob_win\"] - df[\"away_prob_win\"]\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:41.717744Z","iopub.execute_input":"2025-11-20T05:17:41.718165Z","iopub.status.idle":"2025-11-20T05:17:41.751465Z","shell.execute_reply.started":"2025-11-20T05:17:41.718134Z","shell.execute_reply":"2025-11-20T05:17:41.749912Z"},"papermill":{"duration":0.032909,"end_time":"2025-10-27T06:12:22.977549","exception":false,"start_time":"2025-10-27T06:12:22.94464","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"## Dataset Assembly","metadata":{"papermill":{"duration":0.006577,"end_time":"2025-10-27T06:12:22.990933","exception":false,"start_time":"2025-10-27T06:12:22.984356","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Load and prepare datasets\n\nraw_matches_df = pd.read_csv(\n    LEAGUE_RESULTS_PATH,\n    parse_dates=[\"match_datetime_utc\", \"match_date\"],\n)\nraw_matches_df[\"is_result\"] = raw_matches_df[\"is_result\"].astype(str).str.lower() == \"true\"\n\n# Filter to completed fixtures for the configured league\nleague_filtered_df = raw_matches_df.loc[raw_matches_df[\"league\"] == LEAGUE].copy()\nmatch_features_df = (\n    league_filtered_df.loc[league_filtered_df[\"is_result\"]]\n    .assign(\n        season=lambda df: df[\"season\"].astype(str),\n        match_date=lambda df: pd.to_datetime(df[\"match_date\"], errors=\"coerce\"),\n        home_team=lambda df: df[\"home_team_name\"],\n        away_team=lambda df: df[\"away_team_name\"],\n        home_prob_win=lambda df: df[\"forecast_home_win\"].astype(float),\n        draw_prob=lambda df: df[\"forecast_draw\"].astype(float),\n        away_prob_win=lambda df: df[\"forecast_away_win\"].astype(float),\n        home_prob_loss=lambda df: df[\"forecast_away_win\"].astype(float),\n        away_prob_loss=lambda df: df[\"forecast_home_win\"].astype(float),\n        match_draw_prob=lambda df: df[\"forecast_draw\"].astype(float),\n        prob_edge=lambda df: df[\"forecast_home_win\"].astype(float) - df[\"forecast_away_win\"].astype(float),\n        match_day_index=lambda df: (df[\"match_date\"] - df[\"match_date\"].min()).dt.days.astype(float),\n        match_day_of_year=lambda df: df[\"match_date\"].dt.dayofyear.astype(float),\n        match_day_of_year_norm=lambda df: df[\"match_date\"].dt.dayofyear.astype(float) / 366.0,\n        match_weekday_index=lambda df: df[\"match_date\"].dt.weekday.astype(float),\n        match_weekday=lambda df: df[\"match_weekday\"] if \"match_weekday\" in df else df[\"match_date\"].dt.day_name(),\n        target=lambda df: resolve_outcome_target(df),\n    )\n    .sort_values(\"match_datetime_utc\")\n    .reset_index(drop=True)\n)\n\nweekday_dummies = pd.get_dummies(match_features_df[\"match_weekday\"], prefix=\"match_weekday\", dtype=float)\nmatch_features_df = pd.concat([match_features_df, weekday_dummies], axis=1)\nweekday_cols = [col for col in match_features_df.columns if col.startswith(\"match_weekday_\") and \"match_weekday_index\" not in col]\n\nnumeric_prefixes = (\n    \"home_\",\n    \"away_\",\n    \"form_\",\n    \"market_\",\n    \"rest_\",\n    \"season_phase\",\n    \"xg_\",\n    \"forecast_\",\n    \"goal_\",\n    \"total_\",\n    \"prob_\",\n    \"match_\",\n    \"momentum_\",\n    \"elo_\",\n    \"shot_\",\n    \"shots_\",\n)\nnon_numeric_feature_columns = {\n    \"home_team\",\n    \"away_team\",\n    \"home_team_name\",\n    \"away_team_name\",\n    \"home_team_short\",\n    \"away_team_short\",\n    \"match_datetime_utc\",\n    \"match_date\",\n    \"match_time\",\n    \"match_weekday\",\n    \"match_outcome\",\n    \"match_outcome_code\",\n}\nprefixed_cols = [\n    col\n    for col in match_features_df.columns\n    if col.startswith(numeric_prefixes) and col not in non_numeric_feature_columns\n]\nmatch_features_df[prefixed_cols] = match_features_df[prefixed_cols].apply(pd.to_numeric, errors=\"coerce\")\n\n\ndef _prior_rolling_mean(df: pd.DataFrame, team_col: str, value_col: str, window: int) -> pd.Series:\n    series = (\n        df.groupby(team_col, sort=False)[value_col]\n        .transform(lambda s: s.rolling(window, min_periods=1).mean().shift(1))\n    )\n    fallback = df.groupby(team_col, sort=False)[value_col].transform(lambda s: s.shift(1))\n    median = df[value_col].median(skipna=True)\n    return series.fillna(fallback).fillna(median if pd.notna(median) else 0.0).astype(np.float32)\n\n\ndef _season_zscore(df: pd.DataFrame, column: str) -> pd.Series:\n    grouped = df.groupby(\"season\")[column]\n    mean = grouped.transform(\"mean\")\n    std = grouped.transform(\"std\").replace(0.0, np.nan)\n    z = (df[column] - mean) / std\n    return z.replace([np.inf, -np.inf], 0.0).fillna(0.0).astype(np.float32)\n\n\n# Elo-derived strength features\nelo_cols = [\"elo_home_pre\", \"elo_away_pre\", \"elo_home_expectation\"]\nfor col in elo_cols:\n    if col in match_features_df.columns:\n        match_features_df[col] = pd.to_numeric(match_features_df[col], errors=\"coerce\")\n        if match_features_df[col].notna().any():\n            match_features_df[col] = match_features_df[col].fillna(match_features_df[col].median())\n        else:\n            match_features_df[col] = match_features_df[col].fillna(0.0)\n\nif {\"elo_home_pre\", \"elo_away_pre\"}.issubset(match_features_df.columns):\n    match_features_df[\"elo_mean_pre\"] = (\n        match_features_df[\"elo_home_pre\"] + match_features_df[\"elo_away_pre\"]\n    ) / 2.0\n    match_features_df[\"elo_gap_pre\"] = match_features_df[\"elo_home_pre\"] - match_features_df[\"elo_away_pre\"]\n    match_features_df[\"elo_gap_pre_season_z\"] = _season_zscore(match_features_df, \"elo_gap_pre\")\n\nif \"elo_home_expectation\" in match_features_df.columns:\n    match_features_df[\"elo_away_expectation\"] = 1.0 - match_features_df[\"elo_home_expectation\"]\n    match_features_df[\"elo_expectation_gap\"] = match_features_df[\"elo_home_expectation\"] - match_features_df[\"elo_away_expectation\"]\nelse:\n    match_features_df[\"elo_home_expectation\"] = 0.5\n    match_features_df[\"elo_away_expectation\"] = 0.5\n    match_features_df[\"elo_expectation_gap\"] = 0.0\n\nmatch_features_df[\"market_vs_elo_edge\"] = (\n    match_features_df.get(\"forecast_home_win\", 0.0) - match_features_df.get(\"elo_home_expectation\", 0.5)\n).astype(np.float32)\n\n# Shot volume and suppression trends\nif {\"home_shots_for\", \"away_shots_for\"}.issubset(match_features_df.columns):\n    for col in [\"home_shots_for\", \"away_shots_for\"]:\n        match_features_df[col] = pd.to_numeric(match_features_df[col], errors=\"coerce\")\n        if match_features_df[col].notna().any():\n            match_features_df[col] = match_features_df[col].fillna(match_features_df[col].median())\n        else:\n            match_features_df[col] = match_features_df[col].fillna(0.0)\n\n    match_features_df[\"home_shots_allowed\"] = match_features_df[\"away_shots_for\"]\n    match_features_df[\"away_shots_allowed\"] = match_features_df[\"home_shots_for\"]\n\n    match_features_df[\"home_shots_for_avg5\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_for\", ROLLING_WINDOW)\n    match_features_df[\"away_shots_for_avg5\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_for\", ROLLING_WINDOW)\n    match_features_df[\"home_shots_allowed_avg5\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_allowed\", ROLLING_WINDOW)\n    match_features_df[\"away_shots_allowed_avg5\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_allowed\", ROLLING_WINDOW)\n\n    short_window = min(3, ROLLING_WINDOW)\n    match_features_df[\"home_shots_for_avg3\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_for\", short_window)\n    match_features_df[\"away_shots_for_avg3\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_for\", short_window)\n    match_features_df[\"home_shots_allowed_avg3\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_allowed\", short_window)\n    match_features_df[\"away_shots_allowed_avg3\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_allowed\", short_window)\n\n    match_features_df[\"shot_vol_gap_avg5\"] = match_features_df[\"home_shots_for_avg5\"] - match_features_df[\"away_shots_for_avg5\"]\n    match_features_df[\"shot_suppress_gap_avg5\"] = match_features_df[\"away_shots_allowed_avg5\"] - match_features_df[\"home_shots_allowed_avg5\"]\n    match_features_df[\"log_shot_ratio_avg5\"] = np.log(\n        (match_features_df[\"home_shots_for_avg5\"] + 1e-3)\n        / (match_features_df[\"away_shots_for_avg5\"] + 1e-3)\n    )\n    match_features_df[\"shots_tempo_avg5\"] = (\n        match_features_df[\"home_shots_for_avg5\"] + match_features_df[\"away_shots_for_avg5\"]\n    ) / 2.0\n\n    match_features_df[\"shot_volume_gap_avg3\"] = match_features_df[\"home_shots_for_avg3\"] - match_features_df[\"away_shots_for_avg3\"]\n    match_features_df[\"shot_suppress_gap_avg3\"] = match_features_df[\"away_shots_allowed_avg3\"] - match_features_df[\"home_shots_allowed_avg3\"]\n    match_features_df[\"shots_tempo_avg3\"] = (\n        match_features_df[\"home_shots_for_avg3\"] + match_features_df[\"away_shots_for_avg3\"]\n    ) / 2.0\n\n    match_features_df[\"shot_volume_gap_avg3_season_z\"] = _season_zscore(match_features_df, \"shot_volume_gap_avg3\")\n    match_features_df[\"shot_suppress_gap_avg3_season_z\"] = _season_zscore(match_features_df, \"shot_suppress_gap_avg3\")\n    match_features_df[\"shots_tempo_avg3_season_z\"] = _season_zscore(match_features_df, \"shots_tempo_avg3\")\n\n    shot_cols_to_clean = [\n        \"home_shots_for_avg5\",\n        \"away_shots_for_avg5\",\n        \"home_shots_allowed_avg5\",\n        \"away_shots_allowed_avg5\",\n        \"home_shots_for_avg3\",\n        \"away_shots_for_avg3\",\n        \"home_shots_allowed_avg3\",\n        \"away_shots_allowed_avg3\",\n        \"shot_vol_gap_avg5\",\n        \"shot_suppress_gap_avg5\",\n        \"shot_volume_gap_avg3\",\n        \"shot_suppress_gap_avg3\",\n        \"shots_tempo_avg5\",\n        \"shots_tempo_avg3\",\n    ]\n    for col in shot_cols_to_clean:\n        match_features_df[col] = match_features_df[col].astype(np.float32).fillna(0.0)\n\n    match_features_df[\"log_shot_ratio_avg5\"] = (\n        match_features_df[\"log_shot_ratio_avg5\"].replace([np.inf, -np.inf], 0.0).fillna(0.0).astype(np.float32)\n    )\nelse:\n    match_features_df[\"log_shot_ratio_avg5\"] = 0.0\n\nprint(\n    f\"Prepared {len(match_features_df)} completed fixtures from {LEAGUE_RESULTS_PATH.name} spanning seasons {sorted(match_features_df['season'].unique())} for league {LEAGUE}\"\n)\n\ndisplay(match_features_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:41.769233Z","iopub.execute_input":"2025-11-20T05:17:41.769564Z","iopub.status.idle":"2025-11-20T05:17:42.236170Z","shell.execute_reply.started":"2025-11-20T05:17:41.769542Z","shell.execute_reply":"2025-11-20T05:17:42.234932Z"},"papermill":{"duration":0.25536,"end_time":"2025-10-27T06:12:23.252719","exception":false,"start_time":"2025-10-27T06:12:22.997359","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_48/529295480.py:109: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"elo_mean_pre\"] = (\n/tmp/ipykernel_48/529295480.py:112: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"elo_gap_pre\"] = match_features_df[\"elo_home_pre\"] - match_features_df[\"elo_away_pre\"]\n/tmp/ipykernel_48/529295480.py:113: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"elo_gap_pre_season_z\"] = _season_zscore(match_features_df, \"elo_gap_pre\")\n/tmp/ipykernel_48/529295480.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"elo_away_expectation\"] = 1.0 - match_features_df[\"elo_home_expectation\"]\n/tmp/ipykernel_48/529295480.py:117: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"elo_expectation_gap\"] = match_features_df[\"elo_home_expectation\"] - match_features_df[\"elo_away_expectation\"]\n/tmp/ipykernel_48/529295480.py:123: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"market_vs_elo_edge\"] = (\n/tmp/ipykernel_48/529295480.py:136: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"home_shots_allowed\"] = match_features_df[\"away_shots_for\"]\n/tmp/ipykernel_48/529295480.py:137: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"away_shots_allowed\"] = match_features_df[\"home_shots_for\"]\n/tmp/ipykernel_48/529295480.py:139: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"home_shots_for_avg5\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_for\", ROLLING_WINDOW)\n/tmp/ipykernel_48/529295480.py:140: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"away_shots_for_avg5\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_for\", ROLLING_WINDOW)\n/tmp/ipykernel_48/529295480.py:141: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"home_shots_allowed_avg5\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_allowed\", ROLLING_WINDOW)\n/tmp/ipykernel_48/529295480.py:142: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"away_shots_allowed_avg5\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_allowed\", ROLLING_WINDOW)\n/tmp/ipykernel_48/529295480.py:145: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"home_shots_for_avg3\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_for\", short_window)\n/tmp/ipykernel_48/529295480.py:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"away_shots_for_avg3\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_for\", short_window)\n/tmp/ipykernel_48/529295480.py:147: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"home_shots_allowed_avg3\"] = _prior_rolling_mean(match_features_df, \"home_team\", \"home_shots_allowed\", short_window)\n/tmp/ipykernel_48/529295480.py:148: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"away_shots_allowed_avg3\"] = _prior_rolling_mean(match_features_df, \"away_team\", \"away_shots_allowed\", short_window)\n/tmp/ipykernel_48/529295480.py:150: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shot_vol_gap_avg5\"] = match_features_df[\"home_shots_for_avg5\"] - match_features_df[\"away_shots_for_avg5\"]\n/tmp/ipykernel_48/529295480.py:151: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shot_suppress_gap_avg5\"] = match_features_df[\"away_shots_allowed_avg5\"] - match_features_df[\"home_shots_allowed_avg5\"]\n/tmp/ipykernel_48/529295480.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"log_shot_ratio_avg5\"] = np.log(\n/tmp/ipykernel_48/529295480.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shots_tempo_avg5\"] = (\n/tmp/ipykernel_48/529295480.py:160: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shot_volume_gap_avg3\"] = match_features_df[\"home_shots_for_avg3\"] - match_features_df[\"away_shots_for_avg3\"]\n/tmp/ipykernel_48/529295480.py:161: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shot_suppress_gap_avg3\"] = match_features_df[\"away_shots_allowed_avg3\"] - match_features_df[\"home_shots_allowed_avg3\"]\n/tmp/ipykernel_48/529295480.py:162: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shots_tempo_avg3\"] = (\n/tmp/ipykernel_48/529295480.py:166: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shot_volume_gap_avg3_season_z\"] = _season_zscore(match_features_df, \"shot_volume_gap_avg3\")\n/tmp/ipykernel_48/529295480.py:167: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shot_suppress_gap_avg3_season_z\"] = _season_zscore(match_features_df, \"shot_suppress_gap_avg3\")\n/tmp/ipykernel_48/529295480.py:168: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  match_features_df[\"shots_tempo_avg3_season_z\"] = _season_zscore(match_features_df, \"shots_tempo_avg3\")\n","output_type":"stream"},{"name":"stdout","text":"Prepared 1140 completed fixtures from Dataset_Version_3.csv spanning seasons ['2022', '2023', '2024'] for league EPL\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   match_id league season  match_datetime_utc match_date match_weekday  \\\n0     18202    EPL   2022 2022-08-05 19:00:00 2022-08-05        Friday   \n1     18203    EPL   2022 2022-08-06 11:30:00 2022-08-06      Saturday   \n2     18204    EPL   2022 2022-08-06 14:00:00 2022-08-06      Saturday   \n3     18205    EPL   2022 2022-08-06 14:00:00 2022-08-06      Saturday   \n4     18206    EPL   2022 2022-08-06 14:00:00 2022-08-06      Saturday   \n\n   home_team_id    home_team_name  away_team_id           away_team_name  \\\n0            78    Crystal Palace            83                  Arsenal   \n1           228            Fulham            87                Liverpool   \n2            73       Bournemouth            71              Aston Villa   \n3           245             Leeds           229  Wolverhampton Wanderers   \n4            86  Newcastle United           249        Nottingham Forest   \n\n   home_goals  away_goals  total_goals  goal_difference   home_xg   away_xg  \\\n0           0           2            2               -2  1.206370  1.436010   \n1           2           2            4                0  1.268220  2.341110   \n2           2           0            2                2  0.588341  0.488895   \n3           2           1            3                1  0.889170  1.101190   \n4           2           0            2                2  1.859100  0.235825   \n\n   xg_difference match_outcome match_outcome_code outcome_label  outcome_id  \\\n0      -0.229640      Away Win                  A             A           0   \n1      -1.072890          Draw                  D             D           1   \n2       0.099446      Home Win                  H             H           2   \n3      -0.212020      Home Win                  H             H           2   \n4       1.623275      Home Win                  H             H           2   \n\n   home_win_flag  draw_flag  away_win_flag  home_points_actual  \\\n0              0          0              1                   0   \n1              0          1              0                   1   \n2              1          0              0                   3   \n3              1          0              0                   3   \n4              1          0              0                   3   \n\n   away_points_actual  forecast_home_win  forecast_draw  forecast_away_win  \\\n0                   3             0.2864         0.2912             0.4224   \n1                   1             0.1225         0.2133             0.6642   \n2                   0             0.3213         0.4397             0.2390   \n3                   0             0.2798         0.3166             0.4036   \n4                   0             0.8023         0.1695             0.0282   \n\n   market_home_edge  market_expected_points_home  market_expected_points_away  \\\n0           -0.1360                       1.1504                       1.5584   \n1           -0.5417                       0.5808                       2.2059   \n2            0.0823                       1.4036                       1.1567   \n3           -0.1238                       1.1560                       1.5274   \n4            0.7741                       2.5764                       0.2541   \n\n   market_entropy  market_logit_home  market_max_prob  away_goal_diff_last_5  \\\n0        1.081397          -0.388563           0.4224                    0.0   \n1        0.858539          -1.690472           0.6642                    0.0   \n2        1.068161           0.295912           0.4397                    0.0   \n3        1.086701          -0.366349           0.4036                    0.0   \n4        0.578201           3.348161           0.8023                    0.0   \n\n   away_goals_against_last_5  away_goals_for_last_5  away_points_last_5  \\\n0                        0.0                    0.0                 0.0   \n1                        0.0                    0.0                 0.0   \n2                        0.0                    0.0                 0.0   \n3                        0.0                    0.0                 0.0   \n4                        0.0                    0.0                 0.0   \n\n   away_xg_against_last_5  away_xg_diff_last_5  away_xg_for_last_5  \\\n0                     0.0                  0.0                 0.0   \n1                     0.0                  0.0                 0.0   \n2                     0.0                  0.0                 0.0   \n3                     0.0                  0.0                 0.0   \n4                     0.0                  0.0                 0.0   \n\n   form_diff_last5  form_diff_last5_season_mean  form_diff_last5_season_std  \\\n0              0.0                    -0.234211                    4.837233   \n1              0.0                    -0.234211                    4.837233   \n2              0.0                    -0.234211                    4.837233   \n3              0.0                    -0.234211                    4.837233   \n4              0.0                    -0.234211                    4.837233   \n\n   form_diff_last5_season_var  form_diff_last5_season_z  form_pct_diff_last5  \\\n0                   23.398829                  0.048418                  0.0   \n1                   23.398829                  0.048418                  0.0   \n2                   23.398829                  0.048418                  0.0   \n3                   23.398829                  0.048418                  0.0   \n4                   23.398829                  0.048418                  0.0   \n\n   form_pct_diff_last5_season_mean  form_pct_diff_last5_season_std  ...  \\\n0                        -0.018553                        0.339625  ...   \n1                        -0.018553                        0.339625  ...   \n2                        -0.018553                        0.339625  ...   \n3                        -0.018553                        0.339625  ...   \n4                        -0.018553                        0.339625  ...   \n\n   match_weekday_index_season_z  home_shots_for  away_shots_for  elo_home_pre  \\\n0                     -0.213939              11              10        1500.0   \n1                      0.346728               9              11        1500.0   \n2                      0.346728               7              15        1500.0   \n3                      0.346728              12              16        1500.0   \n4                      0.346728              23               5        1500.0   \n\n   elo_away_pre  elo_home_expectation         home_team  \\\n0        1500.0                  0.55    Crystal Palace   \n1        1500.0                  0.55            Fulham   \n2        1500.0                  0.55       Bournemouth   \n3        1500.0                  0.55             Leeds   \n4        1500.0                  0.55  Newcastle United   \n\n                 away_team  home_prob_win  draw_prob  away_prob_win  \\\n0                  Arsenal         0.2864     0.2912         0.4224   \n1                Liverpool         0.1225     0.2133         0.6642   \n2              Aston Villa         0.3213     0.4397         0.2390   \n3  Wolverhampton Wanderers         0.2798     0.3166         0.4036   \n4        Nottingham Forest         0.8023     0.1695         0.0282   \n\n   home_prob_loss  away_prob_loss  match_draw_prob  prob_edge  \\\n0          0.4224          0.2864           0.2912    -0.1360   \n1          0.6642          0.1225           0.2133    -0.5417   \n2          0.2390          0.3213           0.4397     0.0823   \n3          0.4036          0.2798           0.3166    -0.1238   \n4          0.0282          0.8023           0.1695     0.7741   \n\n   match_day_of_year  target  match_weekday_Friday  match_weekday_Monday  \\\n0              217.0       2                   1.0                   0.0   \n1              218.0       1                   0.0                   0.0   \n2              218.0       0                   0.0                   0.0   \n3              218.0       0                   0.0                   0.0   \n4              218.0       0                   0.0                   0.0   \n\n   match_weekday_Saturday  match_weekday_Sunday  match_weekday_Thursday  \\\n0                     0.0                   0.0                     0.0   \n1                     1.0                   0.0                     0.0   \n2                     1.0                   0.0                     0.0   \n3                     1.0                   0.0                     0.0   \n4                     1.0                   0.0                     0.0   \n\n   match_weekday_Tuesday  match_weekday_Wednesday  elo_mean_pre  elo_gap_pre  \\\n0                    0.0                      0.0        1500.0          0.0   \n1                    0.0                      0.0        1500.0          0.0   \n2                    0.0                      0.0        1500.0          0.0   \n3                    0.0                      0.0        1500.0          0.0   \n4                    0.0                      0.0        1500.0          0.0   \n\n   elo_gap_pre_season_z  elo_away_expectation  elo_expectation_gap  \\\n0              0.019232                  0.45                  0.1   \n1              0.019232                  0.45                  0.1   \n2              0.019232                  0.45                  0.1   \n3              0.019232                  0.45                  0.1   \n4              0.019232                  0.45                  0.1   \n\n   market_vs_elo_edge  home_shots_allowed  away_shots_allowed  \\\n0             -0.2636                  10                  11   \n1             -0.4275                  11                   9   \n2             -0.2287                  15                   7   \n3             -0.2702                  16                  12   \n4              0.2523                   5                  23   \n\n   home_shots_for_avg5  away_shots_for_avg5  home_shots_allowed_avg5  \\\n0                 14.0                 11.0                     11.0   \n1                 14.0                 11.0                     11.0   \n2                 14.0                 11.0                     11.0   \n3                 14.0                 11.0                     11.0   \n4                 14.0                 11.0                     11.0   \n\n   away_shots_allowed_avg5  home_shots_for_avg3  away_shots_for_avg3  \\\n0                     14.0                 14.0                 11.0   \n1                     14.0                 14.0                 11.0   \n2                     14.0                 14.0                 11.0   \n3                     14.0                 14.0                 11.0   \n4                     14.0                 14.0                 11.0   \n\n   home_shots_allowed_avg3  away_shots_allowed_avg3  shot_vol_gap_avg5  \\\n0                     11.0                     14.0                3.0   \n1                     11.0                     14.0                3.0   \n2                     11.0                     14.0                3.0   \n3                     11.0                     14.0                3.0   \n4                     11.0                     14.0                3.0   \n\n   shot_suppress_gap_avg5  log_shot_ratio_avg5  shots_tempo_avg5  \\\n0                     3.0             0.241143              12.5   \n1                     3.0             0.241143              12.5   \n2                     3.0             0.241143              12.5   \n3                     3.0             0.241143              12.5   \n4                     3.0             0.241143              12.5   \n\n   shot_volume_gap_avg3  shot_suppress_gap_avg3  shots_tempo_avg3  \\\n0                   3.0                     3.0              12.5   \n1                   3.0                     3.0              12.5   \n2                   3.0                     3.0              12.5   \n3                   3.0                     3.0              12.5   \n4                   3.0                     3.0              12.5   \n\n   shot_volume_gap_avg3_season_z  shot_suppress_gap_avg3_season_z  \\\n0                       0.079678                         0.090844   \n1                       0.079678                         0.090844   \n2                       0.079678                         0.090844   \n3                       0.079678                         0.090844   \n4                       0.079678                         0.090844   \n\n   shots_tempo_avg3_season_z  \n0                  -0.065995  \n1                  -0.065995  \n2                  -0.065995  \n3                  -0.065995  \n4                  -0.065995  \n\n[5 rows x 217 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>match_id</th>\n      <th>league</th>\n      <th>season</th>\n      <th>match_datetime_utc</th>\n      <th>match_date</th>\n      <th>match_weekday</th>\n      <th>home_team_id</th>\n      <th>home_team_name</th>\n      <th>away_team_id</th>\n      <th>away_team_name</th>\n      <th>home_goals</th>\n      <th>away_goals</th>\n      <th>total_goals</th>\n      <th>goal_difference</th>\n      <th>home_xg</th>\n      <th>away_xg</th>\n      <th>xg_difference</th>\n      <th>match_outcome</th>\n      <th>match_outcome_code</th>\n      <th>outcome_label</th>\n      <th>outcome_id</th>\n      <th>home_win_flag</th>\n      <th>draw_flag</th>\n      <th>away_win_flag</th>\n      <th>home_points_actual</th>\n      <th>away_points_actual</th>\n      <th>forecast_home_win</th>\n      <th>forecast_draw</th>\n      <th>forecast_away_win</th>\n      <th>market_home_edge</th>\n      <th>market_expected_points_home</th>\n      <th>market_expected_points_away</th>\n      <th>market_entropy</th>\n      <th>market_logit_home</th>\n      <th>market_max_prob</th>\n      <th>away_goal_diff_last_5</th>\n      <th>away_goals_against_last_5</th>\n      <th>away_goals_for_last_5</th>\n      <th>away_points_last_5</th>\n      <th>away_xg_against_last_5</th>\n      <th>away_xg_diff_last_5</th>\n      <th>away_xg_for_last_5</th>\n      <th>form_diff_last5</th>\n      <th>form_diff_last5_season_mean</th>\n      <th>form_diff_last5_season_std</th>\n      <th>form_diff_last5_season_var</th>\n      <th>form_diff_last5_season_z</th>\n      <th>form_pct_diff_last5</th>\n      <th>form_pct_diff_last5_season_mean</th>\n      <th>form_pct_diff_last5_season_std</th>\n      <th>...</th>\n      <th>match_weekday_index_season_z</th>\n      <th>home_shots_for</th>\n      <th>away_shots_for</th>\n      <th>elo_home_pre</th>\n      <th>elo_away_pre</th>\n      <th>elo_home_expectation</th>\n      <th>home_team</th>\n      <th>away_team</th>\n      <th>home_prob_win</th>\n      <th>draw_prob</th>\n      <th>away_prob_win</th>\n      <th>home_prob_loss</th>\n      <th>away_prob_loss</th>\n      <th>match_draw_prob</th>\n      <th>prob_edge</th>\n      <th>match_day_of_year</th>\n      <th>target</th>\n      <th>match_weekday_Friday</th>\n      <th>match_weekday_Monday</th>\n      <th>match_weekday_Saturday</th>\n      <th>match_weekday_Sunday</th>\n      <th>match_weekday_Thursday</th>\n      <th>match_weekday_Tuesday</th>\n      <th>match_weekday_Wednesday</th>\n      <th>elo_mean_pre</th>\n      <th>elo_gap_pre</th>\n      <th>elo_gap_pre_season_z</th>\n      <th>elo_away_expectation</th>\n      <th>elo_expectation_gap</th>\n      <th>market_vs_elo_edge</th>\n      <th>home_shots_allowed</th>\n      <th>away_shots_allowed</th>\n      <th>home_shots_for_avg5</th>\n      <th>away_shots_for_avg5</th>\n      <th>home_shots_allowed_avg5</th>\n      <th>away_shots_allowed_avg5</th>\n      <th>home_shots_for_avg3</th>\n      <th>away_shots_for_avg3</th>\n      <th>home_shots_allowed_avg3</th>\n      <th>away_shots_allowed_avg3</th>\n      <th>shot_vol_gap_avg5</th>\n      <th>shot_suppress_gap_avg5</th>\n      <th>log_shot_ratio_avg5</th>\n      <th>shots_tempo_avg5</th>\n      <th>shot_volume_gap_avg3</th>\n      <th>shot_suppress_gap_avg3</th>\n      <th>shots_tempo_avg3</th>\n      <th>shot_volume_gap_avg3_season_z</th>\n      <th>shot_suppress_gap_avg3_season_z</th>\n      <th>shots_tempo_avg3_season_z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18202</td>\n      <td>EPL</td>\n      <td>2022</td>\n      <td>2022-08-05 19:00:00</td>\n      <td>2022-08-05</td>\n      <td>Friday</td>\n      <td>78</td>\n      <td>Crystal Palace</td>\n      <td>83</td>\n      <td>Arsenal</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>-2</td>\n      <td>1.206370</td>\n      <td>1.436010</td>\n      <td>-0.229640</td>\n      <td>Away Win</td>\n      <td>A</td>\n      <td>A</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.2864</td>\n      <td>0.2912</td>\n      <td>0.4224</td>\n      <td>-0.1360</td>\n      <td>1.1504</td>\n      <td>1.5584</td>\n      <td>1.081397</td>\n      <td>-0.388563</td>\n      <td>0.4224</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.234211</td>\n      <td>4.837233</td>\n      <td>23.398829</td>\n      <td>0.048418</td>\n      <td>0.0</td>\n      <td>-0.018553</td>\n      <td>0.339625</td>\n      <td>...</td>\n      <td>-0.213939</td>\n      <td>11</td>\n      <td>10</td>\n      <td>1500.0</td>\n      <td>1500.0</td>\n      <td>0.55</td>\n      <td>Crystal Palace</td>\n      <td>Arsenal</td>\n      <td>0.2864</td>\n      <td>0.2912</td>\n      <td>0.4224</td>\n      <td>0.4224</td>\n      <td>0.2864</td>\n      <td>0.2912</td>\n      <td>-0.1360</td>\n      <td>217.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1500.0</td>\n      <td>0.0</td>\n      <td>0.019232</td>\n      <td>0.45</td>\n      <td>0.1</td>\n      <td>-0.2636</td>\n      <td>10</td>\n      <td>11</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.241143</td>\n      <td>12.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>12.5</td>\n      <td>0.079678</td>\n      <td>0.090844</td>\n      <td>-0.065995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18203</td>\n      <td>EPL</td>\n      <td>2022</td>\n      <td>2022-08-06 11:30:00</td>\n      <td>2022-08-06</td>\n      <td>Saturday</td>\n      <td>228</td>\n      <td>Fulham</td>\n      <td>87</td>\n      <td>Liverpool</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1.268220</td>\n      <td>2.341110</td>\n      <td>-1.072890</td>\n      <td>Draw</td>\n      <td>D</td>\n      <td>D</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.1225</td>\n      <td>0.2133</td>\n      <td>0.6642</td>\n      <td>-0.5417</td>\n      <td>0.5808</td>\n      <td>2.2059</td>\n      <td>0.858539</td>\n      <td>-1.690472</td>\n      <td>0.6642</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.234211</td>\n      <td>4.837233</td>\n      <td>23.398829</td>\n      <td>0.048418</td>\n      <td>0.0</td>\n      <td>-0.018553</td>\n      <td>0.339625</td>\n      <td>...</td>\n      <td>0.346728</td>\n      <td>9</td>\n      <td>11</td>\n      <td>1500.0</td>\n      <td>1500.0</td>\n      <td>0.55</td>\n      <td>Fulham</td>\n      <td>Liverpool</td>\n      <td>0.1225</td>\n      <td>0.2133</td>\n      <td>0.6642</td>\n      <td>0.6642</td>\n      <td>0.1225</td>\n      <td>0.2133</td>\n      <td>-0.5417</td>\n      <td>218.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1500.0</td>\n      <td>0.0</td>\n      <td>0.019232</td>\n      <td>0.45</td>\n      <td>0.1</td>\n      <td>-0.4275</td>\n      <td>11</td>\n      <td>9</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.241143</td>\n      <td>12.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>12.5</td>\n      <td>0.079678</td>\n      <td>0.090844</td>\n      <td>-0.065995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18204</td>\n      <td>EPL</td>\n      <td>2022</td>\n      <td>2022-08-06 14:00:00</td>\n      <td>2022-08-06</td>\n      <td>Saturday</td>\n      <td>73</td>\n      <td>Bournemouth</td>\n      <td>71</td>\n      <td>Aston Villa</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.588341</td>\n      <td>0.488895</td>\n      <td>0.099446</td>\n      <td>Home Win</td>\n      <td>H</td>\n      <td>H</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.3213</td>\n      <td>0.4397</td>\n      <td>0.2390</td>\n      <td>0.0823</td>\n      <td>1.4036</td>\n      <td>1.1567</td>\n      <td>1.068161</td>\n      <td>0.295912</td>\n      <td>0.4397</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.234211</td>\n      <td>4.837233</td>\n      <td>23.398829</td>\n      <td>0.048418</td>\n      <td>0.0</td>\n      <td>-0.018553</td>\n      <td>0.339625</td>\n      <td>...</td>\n      <td>0.346728</td>\n      <td>7</td>\n      <td>15</td>\n      <td>1500.0</td>\n      <td>1500.0</td>\n      <td>0.55</td>\n      <td>Bournemouth</td>\n      <td>Aston Villa</td>\n      <td>0.3213</td>\n      <td>0.4397</td>\n      <td>0.2390</td>\n      <td>0.2390</td>\n      <td>0.3213</td>\n      <td>0.4397</td>\n      <td>0.0823</td>\n      <td>218.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1500.0</td>\n      <td>0.0</td>\n      <td>0.019232</td>\n      <td>0.45</td>\n      <td>0.1</td>\n      <td>-0.2287</td>\n      <td>15</td>\n      <td>7</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.241143</td>\n      <td>12.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>12.5</td>\n      <td>0.079678</td>\n      <td>0.090844</td>\n      <td>-0.065995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18205</td>\n      <td>EPL</td>\n      <td>2022</td>\n      <td>2022-08-06 14:00:00</td>\n      <td>2022-08-06</td>\n      <td>Saturday</td>\n      <td>245</td>\n      <td>Leeds</td>\n      <td>229</td>\n      <td>Wolverhampton Wanderers</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.889170</td>\n      <td>1.101190</td>\n      <td>-0.212020</td>\n      <td>Home Win</td>\n      <td>H</td>\n      <td>H</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.2798</td>\n      <td>0.3166</td>\n      <td>0.4036</td>\n      <td>-0.1238</td>\n      <td>1.1560</td>\n      <td>1.5274</td>\n      <td>1.086701</td>\n      <td>-0.366349</td>\n      <td>0.4036</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.234211</td>\n      <td>4.837233</td>\n      <td>23.398829</td>\n      <td>0.048418</td>\n      <td>0.0</td>\n      <td>-0.018553</td>\n      <td>0.339625</td>\n      <td>...</td>\n      <td>0.346728</td>\n      <td>12</td>\n      <td>16</td>\n      <td>1500.0</td>\n      <td>1500.0</td>\n      <td>0.55</td>\n      <td>Leeds</td>\n      <td>Wolverhampton Wanderers</td>\n      <td>0.2798</td>\n      <td>0.3166</td>\n      <td>0.4036</td>\n      <td>0.4036</td>\n      <td>0.2798</td>\n      <td>0.3166</td>\n      <td>-0.1238</td>\n      <td>218.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1500.0</td>\n      <td>0.0</td>\n      <td>0.019232</td>\n      <td>0.45</td>\n      <td>0.1</td>\n      <td>-0.2702</td>\n      <td>16</td>\n      <td>12</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.241143</td>\n      <td>12.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>12.5</td>\n      <td>0.079678</td>\n      <td>0.090844</td>\n      <td>-0.065995</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18206</td>\n      <td>EPL</td>\n      <td>2022</td>\n      <td>2022-08-06 14:00:00</td>\n      <td>2022-08-06</td>\n      <td>Saturday</td>\n      <td>86</td>\n      <td>Newcastle United</td>\n      <td>249</td>\n      <td>Nottingham Forest</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.859100</td>\n      <td>0.235825</td>\n      <td>1.623275</td>\n      <td>Home Win</td>\n      <td>H</td>\n      <td>H</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.8023</td>\n      <td>0.1695</td>\n      <td>0.0282</td>\n      <td>0.7741</td>\n      <td>2.5764</td>\n      <td>0.2541</td>\n      <td>0.578201</td>\n      <td>3.348161</td>\n      <td>0.8023</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.234211</td>\n      <td>4.837233</td>\n      <td>23.398829</td>\n      <td>0.048418</td>\n      <td>0.0</td>\n      <td>-0.018553</td>\n      <td>0.339625</td>\n      <td>...</td>\n      <td>0.346728</td>\n      <td>23</td>\n      <td>5</td>\n      <td>1500.0</td>\n      <td>1500.0</td>\n      <td>0.55</td>\n      <td>Newcastle United</td>\n      <td>Nottingham Forest</td>\n      <td>0.8023</td>\n      <td>0.1695</td>\n      <td>0.0282</td>\n      <td>0.0282</td>\n      <td>0.8023</td>\n      <td>0.1695</td>\n      <td>0.7741</td>\n      <td>218.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1500.0</td>\n      <td>0.0</td>\n      <td>0.019232</td>\n      <td>0.45</td>\n      <td>0.1</td>\n      <td>0.2523</td>\n      <td>5</td>\n      <td>23</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>14.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.241143</td>\n      <td>12.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>12.5</td>\n      <td>0.079678</td>\n      <td>0.090844</td>\n      <td>-0.065995</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 217 columns</p>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## Train/Validation/Test Split","metadata":{"papermill":{"duration":0.007009,"end_time":"2025-10-27T06:12:23.26771","exception":false,"start_time":"2025-10-27T06:12:23.260701","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\n# Chronological train/validation/test split\nsorted_df = match_features_df.sort_values(\"match_date\").reset_index(drop=True)\nnum_matches = len(sorted_df)\ntrain_end = int(num_matches * 0.6)\nval_end = int(num_matches * 0.8)\n\nsplit_indices = {\n    \"train\": sorted_df.index[:train_end],\n    \"val\": sorted_df.index[train_end:val_end],\n    \"test\": sorted_df.index[val_end:],\n}\n\nprint({k: len(v) for k, v in split_indices.items()})\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:42.238197Z","iopub.execute_input":"2025-11-20T05:17:42.238486Z","iopub.status.idle":"2025-11-20T05:17:42.262832Z","shell.execute_reply.started":"2025-11-20T05:17:42.238464Z","shell.execute_reply":"2025-11-20T05:17:42.261580Z"},"papermill":{"duration":0.024651,"end_time":"2025-10-27T06:12:23.299649","exception":false,"start_time":"2025-10-27T06:12:23.274998","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"{'train': 684, 'val': 228, 'test': 228}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## Feature Views","metadata":{"papermill":{"duration":0.007058,"end_time":"2025-10-27T06:12:23.314594","exception":false,"start_time":"2025-10-27T06:12:23.307536","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Feature view utilities\n\nfrom abc import ABC, abstractmethod\n\n\ndef select_features(df: pd.DataFrame, candidates: list[str]) -> list[str]:\n    \"\"\"Return candidate columns present in the dataframe, preserving order.\"\"\"\n    return [col for col in candidates if col in df.columns]\n\n\ndef unique(seq: list[str]) -> list[str]:\n    \"\"\"Deduplicate while preserving order.\"\"\"\n    seen: set[str] = set()\n    ordered: list[str] = []\n    for item in seq:\n        if item not in seen:\n            seen.add(item)\n            ordered.append(item)\n    return ordered\n\n\nclass BaseFeatureView(ABC):\n    \"\"\"Base class for feature view preparation and specs.\"\"\"\n\n    def __init__(self, df: pd.DataFrame) -> None:\n        self.df = df\n        self._feature_cols: list[str] | None = None\n\n    @abstractmethod\n    def prepare(self) -> None:\n        \"\"\"Mutate underlying dataframe with view-specific engineering.\"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def feature_columns(self) -> list[str]:\n        raise NotImplementedError\n\n    def include_market_probs(self) -> bool:\n        return False\n\n    def scale_strategy(self) -> str | None:\n        return None\n\n    def build_spec(self, *, description: str, trainer: str, **extra: object) -> dict[str, object]:\n        spec: dict[str, object] = {\n            \"description\": description,\n            \"feature_cols\": self.feature_columns(),\n            \"trainer\": trainer,\n            **extra,\n        }\n        scale = self.scale_strategy()\n        if scale:\n            spec.setdefault(\"scale_strategy\", scale)\n        if self.include_market_probs():\n            spec.setdefault(\"include_market_probs\", True)\n        return spec\n","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T05:17:42.263991Z","iopub.execute_input":"2025-11-20T05:17:42.264337Z","iopub.status.idle":"2025-11-20T05:17:42.278455Z","shell.execute_reply.started":"2025-11-20T05:17:42.264307Z","shell.execute_reply":"2025-11-20T05:17:42.277113Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Performance data view\n\nclass PerformanceFeatureView(BaseFeatureView):\n    \"\"\"Smoothed per-match aggregates tailored for the dense baseline.\"\"\"\n\n    EPS = 1e-3\n\n    def __init__(self, df: pd.DataFrame, rolling_window: int) -> None:\n        super().__init__(df)\n        self.rolling_window = rolling_window\n\n    @staticmethod\n    def _smoothed_avg(sum_series: pd.Series, games_frac: pd.Series, window: int) -> pd.Series:\n        games = games_frac * window\n        per_match = sum_series / games.replace(0.0, np.nan)\n        prior = per_match.dropna().mean()\n        prior = 0.0 if np.isnan(prior) else prior\n        per_match = per_match.fillna(prior)\n        alpha = games_frac.clip(0.0, 1.0)\n        return (alpha * per_match + (1.0 - alpha) * prior).astype(np.float32)\n\n    def prepare(self) -> None:\n        df = self.df\n        window = self.rolling_window\n\n        if \"home_goals_for_avg5\" not in df.columns:\n            home_games = df.groupby([\"season\", \"home_team\"], sort=False).cumcount().clip(upper=window).astype(float)\n            away_games = df.groupby([\"season\", \"away_team\"], sort=False).cumcount().clip(upper=window).astype(float)\n\n            df[\"home_recent_games_frac\"] = (home_games / window).astype(np.float32)\n            df[\"away_recent_games_frac\"] = (away_games / window).astype(np.float32)\n\n            df[\"home_goals_for_avg5\"] = self._smoothed_avg(df[\"home_goals_for_last_5\"], df[\"home_recent_games_frac\"], window)\n            df[\"home_goals_against_avg5\"] = self._smoothed_avg(df[\"home_goals_against_last_5\"], df[\"home_recent_games_frac\"], window)\n            df[\"home_xg_for_avg5\"] = self._smoothed_avg(df[\"home_xg_for_last_5\"], df[\"home_recent_games_frac\"], window)\n            df[\"home_xg_against_avg5\"] = self._smoothed_avg(df[\"home_xg_against_last_5\"], df[\"home_recent_games_frac\"], window)\n            df[\"home_points_avg5\"] = self._smoothed_avg(df[\"home_points_last_5\"], df[\"home_recent_games_frac\"], window)\n\n            df[\"away_goals_for_avg5\"] = self._smoothed_avg(df[\"away_goals_for_last_5\"], df[\"away_recent_games_frac\"], window)\n            df[\"away_goals_against_avg5\"] = self._smoothed_avg(df[\"away_goals_against_last_5\"], df[\"away_recent_games_frac\"], window)\n            df[\"away_xg_for_avg5\"] = self._smoothed_avg(df[\"away_xg_for_last_5\"], df[\"away_recent_games_frac\"], window)\n            df[\"away_xg_against_avg5\"] = self._smoothed_avg(df[\"away_xg_against_last_5\"], df[\"away_recent_games_frac\"], window)\n            df[\"away_points_avg5\"] = self._smoothed_avg(df[\"away_points_last_5\"], df[\"away_recent_games_frac\"], window)\n\n            df[\"att_gap_avg5\"] = df[\"home_goals_for_avg5\"] - df[\"away_goals_for_avg5\"]\n            df[\"def_gap_avg5\"] = df[\"away_goals_against_avg5\"] - df[\"home_goals_against_avg5\"]\n            df[\"points_gap_avg5\"] = df[\"home_points_avg5\"] - df[\"away_points_avg5\"]\n            df[\"xg_att_gap_avg5\"] = df[\"home_xg_for_avg5\"] - df[\"away_xg_for_avg5\"]\n            df[\"xg_def_gap_avg5\"] = df[\"away_xg_against_avg5\"] - df[\"home_xg_against_avg5\"]\n\n            df[\"log_goal_ratio_avg5\"] = np.log((df[\"home_goals_for_avg5\"] + self.EPS) / (df[\"away_goals_for_avg5\"] + self.EPS))\n            df[\"log_points_ratio_avg5\"] = np.log((df[\"home_points_avg5\"] + self.EPS) / (df[\"away_points_avg5\"] + self.EPS))\n            df[\"log_xg_ratio_avg5\"] = np.log((df[\"home_xg_for_avg5\"] + self.EPS) / (df[\"away_xg_for_avg5\"] + self.EPS))\n\n            df[\"match_day_sin\"] = np.sin(2.0 * np.pi * df[\"match_day_of_year_norm\"].fillna(0.0))\n            df[\"match_day_cos\"] = np.cos(2.0 * np.pi * df[\"match_day_of_year_norm\"].fillna(0.0))\n\n        if \"log_shot_ratio_avg5\" not in df.columns and {\"home_shots_for_avg5\", \"away_shots_for_avg5\"}.issubset(df.columns):\n            df[\"log_shot_ratio_avg5\"] = np.log(\n                (df[\"home_shots_for_avg5\"] + self.EPS)\n                / (df[\"away_shots_for_avg5\"] + self.EPS)\n            )\n\n        ratio_cols = [col for col in [\n            \"log_goal_ratio_avg5\",\n            \"log_points_ratio_avg5\",\n            \"log_xg_ratio_avg5\",\n            \"log_shot_ratio_avg5\",\n        ] if col in df.columns]\n        if ratio_cols:\n            df[ratio_cols] = (\n                df[ratio_cols]\n                .replace([np.inf, -np.inf], 0.0)\n                .fillna(0.0)\n                .astype(np.float32)\n            )\n\n    def feature_columns(self) -> list[str]:\n        if self._feature_cols is None:\n            self.prepare()\n            columns = [\n                \"home_recent_games_frac\",\n                \"away_recent_games_frac\",\n                \"home_shots_for_avg5\",\n                \"home_shots_allowed_avg5\",\n                \"away_shots_for_avg5\",\n                \"away_shots_allowed_avg5\",\n                \"shot_vol_gap_avg5\",\n                \"shot_suppress_gap_avg5\",\n                \"log_shot_ratio_avg5\",\n                \"shots_tempo_avg5\",\n                \"att_gap_avg5\",\n                \"def_gap_avg5\",\n                \"points_gap_avg5\",\n                \"xg_att_gap_avg5\",\n                \"xg_def_gap_avg5\",\n                \"log_xg_ratio_avg5\",\n                \"home_goals_for_avg5\",\n                \"home_goals_against_avg5\",\n                \"away_goals_for_avg5\",\n                \"away_goals_against_avg5\",\n                \"elo_home_pre\",\n                \"elo_away_pre\",\n                \"elo_mean_pre\",\n                \"elo_gap_pre\",\n                \"elo_home_expectation\",\n                \"elo_expectation_gap\",\n                \"market_vs_elo_edge\",\n                \"match_day_sin\",\n                \"match_day_cos\",\n            ]\n            self._feature_cols = unique(select_features(self.df, columns))\n        return self._feature_cols\n\n    def scale_strategy(self) -> str | None:\n        return \"zscore\"\n","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T05:17:42.279571Z","iopub.execute_input":"2025-11-20T05:17:42.279862Z","iopub.status.idle":"2025-11-20T05:17:42.302226Z","shell.execute_reply.started":"2025-11-20T05:17:42.279837Z","shell.execute_reply":"2025-11-20T05:17:42.300974Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Momentum data view\n\nclass MomentumFeatureView(BaseFeatureView):\n    def __init__(self, df: pd.DataFrame, weekday_columns: list[str]) -> None:\n        super().__init__(df)\n        self.weekday_columns = weekday_columns\n\n    def prepare(self) -> None:\n        # Momentum features already materialised during dataset build.\n        return\n\n    def feature_columns(self) -> list[str]:\n        if self._feature_cols is None:\n            base_columns = [\n                \"momentum_points_last3_delta_season_z\",\n                \"momentum_points_last2_delta_season_z\",\n                \"momentum_points_last8_delta_season_z\",\n                \"momentum_points_pct_last3_delta_season_z\",\n                \"momentum_goal_diff_last3_delta_season_z\",\n                \"momentum_goal_diff_last2_delta_season_z\",\n                \"momentum_goal_diff_last8_delta_season_z\",\n                \"momentum_xg_diff_last3_delta_season_z\",\n                \"momentum_xg_diff_last2_delta_season_z\",\n                \"momentum_xg_diff_last8_delta_season_z\",\n                \"momentum_points_exp_decay_delta_season_z\",\n                \"momentum_xg_exp_decay_delta_season_z\",\n                \"momentum_matches_last14_delta_season_z\",\n                \"momentum_travel_rest_ratio_delta_season_z\",\n                \"momentum_forecast_win_prev_delta_season_z\",\n                \"momentum_forecast_trend_delta_season_z\",\n                \"shot_volume_gap_avg3_season_z\",\n                \"shot_suppress_gap_avg3_season_z\",\n                \"shots_tempo_avg3_season_z\",\n                \"elo_gap_pre_season_z\",\n                \"market_vs_elo_edge\",\n                \"form_pct_diff_last5_season_z\",\n                \"form_diff_last5_season_z\",\n                \"rest_diff_season_z\",\n                \"fixture_congestion_flag_pair\",\n                \"momentum_fixture_congestion_delta\",\n                \"rest_reset_flag_pair\",\n                \"match_day_index_season_z\",\n                \"match_day_of_year_norm_season_z\",\n                \"match_weekday_index_season_z\",\n            ]\n            columns = base_columns + self.weekday_columns\n            self._feature_cols = unique(select_features(self.df, columns))\n        return self._feature_cols\n\n    def include_market_probs(self) -> bool:\n        return True\n","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T05:17:42.304653Z","iopub.execute_input":"2025-11-20T05:17:42.304992Z","iopub.status.idle":"2025-11-20T05:17:42.330648Z","shell.execute_reply.started":"2025-11-20T05:17:42.304970Z","shell.execute_reply":"2025-11-20T05:17:42.329502Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Market data view\n\nclass MarketFeatureView(BaseFeatureView):\n    def __init__(self, df: pd.DataFrame, weekday_columns: list[str]) -> None:\n        super().__init__(df)\n        self.weekday_columns = weekday_columns\n\n    def prepare(self) -> None:\n        return\n\n    def feature_columns(self) -> list[str]:\n        if self._feature_cols is None:\n            base_columns = [\n                \"forecast_home_win\",\n                \"forecast_draw\",\n                \"forecast_away_win\",\n                \"market_home_edge\",\n                \"market_entropy\",\n                \"market_logit_home\",\n                \"market_max_prob\",\n                \"prob_edge\",\n                \"elo_home_pre\",\n                \"elo_away_pre\",\n                \"elo_mean_pre\",\n                \"elo_gap_pre\",\n                \"elo_home_expectation\",\n                \"elo_expectation_gap\",\n                \"market_vs_elo_edge\",\n                \"match_day_index\",\n                \"match_day_of_year_norm\",\n                \"match_weekday_index\",\n            ]\n            columns = base_columns + self.weekday_columns\n            self._feature_cols = unique(select_features(self.df, columns))\n        return self._feature_cols\n","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T05:17:42.332245Z","iopub.execute_input":"2025-11-20T05:17:42.332588Z","iopub.status.idle":"2025-11-20T05:17:42.361871Z","shell.execute_reply.started":"2025-11-20T05:17:42.332560Z","shell.execute_reply":"2025-11-20T05:17:42.360673Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# Feature set registry built from view builders\n\nperformance_view = PerformanceFeatureView(match_features_df, ROLLING_WINDOW)\nPERFORMANCE_FEATURES = performance_view.feature_columns()\n\nmomentum_view = MomentumFeatureView(match_features_df, weekday_cols)\nMOMENTUM_FEATURES = momentum_view.feature_columns()\n\nmarket_view = MarketFeatureView(match_features_df, weekday_cols)\nMARKET_FEATURES = market_view.feature_columns()\n\nFEATURE_SETS = {\n    \"performance_dense\": performance_view.build_spec(\n        description=\"Performance-based dense network using smoothed per-match aggregates\",\n        trainer=\"keras\",\n        builder_name=\"build_performance_model\",\n    ),\n    \"momentum_policy_rl\": momentum_view.build_spec(\n        description=\"Momentum-policy REINFORCE agent leveraging short-horizon trends\",\n        trainer=\"reinforce\",\n        policy_hidden_units=[128, 64],\n        gamma=0.95,\n        learning_rate=7e-4,\n        policy_epochs=max(EPOCHS, 60),\n        reward_config={\n            \"draw_correct_bonus\": 0.85,\n            \"market_upset_bonus\": 0.9,\n            \"market_underdog_threshold\": 0.35,\n        },\n    ),\n    \"market_gradient_boost\": market_view.build_spec(\n        description=\"Market odds derived statistics\",\n        trainer=\"xgboost\",\n        xgb_params={\n            \"objective\": \"multi:softprob\",\n            \"learning_rate\": 0.05,\n            \"max_depth\": 4,\n            \"subsample\": 0.85,\n            \"colsample_bytree\": 0.75,\n            \"reg_lambda\": 1.0,\n            \"n_estimators\": 600,\n            \"min_child_weight\": 2,\n            \"random_state\": SEED,\n            \"eval_metric\": \"mlogloss\",\n            \"tree_method\": \"hist\",\n        },\n    ),\n}\n\nprint({name: len(spec[\"feature_cols\"]) for name, spec in FEATURE_SETS.items()})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T05:17:42.363318Z","iopub.execute_input":"2025-11-20T05:17:42.363685Z","iopub.status.idle":"2025-11-20T05:17:42.447603Z","shell.execute_reply.started":"2025-11-20T05:17:42.363658Z","shell.execute_reply":"2025-11-20T05:17:42.446578Z"}},"outputs":[{"name":"stdout","text":"{'performance_dense': 29, 'momentum_policy_rl': 37, 'market_gradient_boost': 25}\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_48/3324865175.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"home_recent_games_frac\"] = (home_games / window).astype(np.float32)\n/tmp/ipykernel_48/3324865175.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"away_recent_games_frac\"] = (away_games / window).astype(np.float32)\n/tmp/ipykernel_48/3324865175.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"home_goals_for_avg5\"] = self._smoothed_avg(df[\"home_goals_for_last_5\"], df[\"home_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"home_goals_against_avg5\"] = self._smoothed_avg(df[\"home_goals_against_last_5\"], df[\"home_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"home_xg_for_avg5\"] = self._smoothed_avg(df[\"home_xg_for_last_5\"], df[\"home_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:36: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"home_xg_against_avg5\"] = self._smoothed_avg(df[\"home_xg_against_last_5\"], df[\"home_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"home_points_avg5\"] = self._smoothed_avg(df[\"home_points_last_5\"], df[\"home_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:39: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"away_goals_for_avg5\"] = self._smoothed_avg(df[\"away_goals_for_last_5\"], df[\"away_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"away_goals_against_avg5\"] = self._smoothed_avg(df[\"away_goals_against_last_5\"], df[\"away_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"away_xg_for_avg5\"] = self._smoothed_avg(df[\"away_xg_for_last_5\"], df[\"away_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"away_xg_against_avg5\"] = self._smoothed_avg(df[\"away_xg_against_last_5\"], df[\"away_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"away_points_avg5\"] = self._smoothed_avg(df[\"away_points_last_5\"], df[\"away_recent_games_frac\"], window)\n/tmp/ipykernel_48/3324865175.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"att_gap_avg5\"] = df[\"home_goals_for_avg5\"] - df[\"away_goals_for_avg5\"]\n/tmp/ipykernel_48/3324865175.py:46: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"def_gap_avg5\"] = df[\"away_goals_against_avg5\"] - df[\"home_goals_against_avg5\"]\n/tmp/ipykernel_48/3324865175.py:47: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"points_gap_avg5\"] = df[\"home_points_avg5\"] - df[\"away_points_avg5\"]\n/tmp/ipykernel_48/3324865175.py:48: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"xg_att_gap_avg5\"] = df[\"home_xg_for_avg5\"] - df[\"away_xg_for_avg5\"]\n/tmp/ipykernel_48/3324865175.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"xg_def_gap_avg5\"] = df[\"away_xg_against_avg5\"] - df[\"home_xg_against_avg5\"]\n/tmp/ipykernel_48/3324865175.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"log_goal_ratio_avg5\"] = np.log((df[\"home_goals_for_avg5\"] + self.EPS) / (df[\"away_goals_for_avg5\"] + self.EPS))\n/tmp/ipykernel_48/3324865175.py:52: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"log_points_ratio_avg5\"] = np.log((df[\"home_points_avg5\"] + self.EPS) / (df[\"away_points_avg5\"] + self.EPS))\n/tmp/ipykernel_48/3324865175.py:53: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"log_xg_ratio_avg5\"] = np.log((df[\"home_xg_for_avg5\"] + self.EPS) / (df[\"away_xg_for_avg5\"] + self.EPS))\n/tmp/ipykernel_48/3324865175.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"match_day_sin\"] = np.sin(2.0 * np.pi * df[\"match_day_of_year_norm\"].fillna(0.0))\n/tmp/ipykernel_48/3324865175.py:56: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[\"match_day_cos\"] = np.cos(2.0 * np.pi * df[\"match_day_of_year_norm\"].fillna(0.0))\n","output_type":"stream"}],"execution_count":45},{"cell_type":"markdown","source":"## TensorFlow Dataset Utilities","metadata":{"papermill":{"duration":0.007303,"end_time":"2025-10-27T06:12:23.373132","exception":false,"start_time":"2025-10-27T06:12:23.365829","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Dataset constructors\n\nMARKET_PROBABILITY_COLUMNS = [\"forecast_home_win\", \"forecast_draw\", \"forecast_away_win\"]\n\n\ndef prepare_view_frame(df: pd.DataFrame, feature_cols: list[str], *, include_market_probs: bool = False) -> pd.DataFrame:\n    base_cols = [\"match_id\", \"season\", \"match_date\", \"target\"]\n    market_cols = MARKET_PROBABILITY_COLUMNS if include_market_probs else []\n    ordered_cols = unique(base_cols + feature_cols + market_cols)\n\n    available_cols = [col for col in ordered_cols if col in df.columns]\n    view = df.loc[:, available_cols].copy()\n\n    missing_cols = [col for col in ordered_cols if col not in available_cols]\n    if missing_cols:\n        augment = match_features_df.loc[:, [\"match_id\", *missing_cols]].drop_duplicates(\"match_id\")\n        view = view.merge(augment, on=\"match_id\", how=\"left\")\n\n    numeric_cols = [col for col in ordered_cols if col not in {\"match_id\", \"season\", \"match_date\"}]\n    view[numeric_cols] = view[numeric_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n\n    return view.reindex(columns=ordered_cols)\n\n\ndef prepare_feature_matrices(\n    df: pd.DataFrame,\n    feature_cols: list[str],\n    split_indices: dict[str, pd.Index],\n    *,\n    scale_strategy: str | None = None,\n) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Return train/val/test feature matrices with optional scaling.\"\"\"\n    matrices = {\n        split: df.loc[split_indices[split], feature_cols].astype(np.float32).to_numpy(copy=True)\n        for split in (\"train\", \"val\", \"test\")\n    }\n    if scale_strategy == \"zscore\":\n        train_matrix = matrices[\"train\"]\n        mean = train_matrix.mean(axis=0, keepdims=True)\n        std = train_matrix.std(axis=0, keepdims=True)\n        std = np.where(std < 1e-6, 1.0, std)\n        matrices = {split: (mat - mean) / std for split, mat in matrices.items()}\n    return matrices[\"train\"], matrices[\"val\"], matrices[\"test\"]\n\n\ndef build_xy(df: pd.DataFrame, feature_cols: list[str], indices: pd.Index) -> tuple[np.ndarray, np.ndarray]:\n    X = df.loc[indices, feature_cols].astype(np.float32).to_numpy()\n    y = df.loc[indices, \"target\"].astype(np.int32).to_numpy()\n    return X, y\n\n\ndef make_dataset(X: np.ndarray, y: np.ndarray, *, training: bool) -> tf.data.Dataset:\n    ds = tf.data.Dataset.from_tensor_slices((X, y))\n    if training:\n        ds = ds.shuffle(buffer_size=len(X), seed=SEED, reshuffle_each_iteration=True)\n    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n\ndef compute_class_weights(y: np.ndarray) -> dict[int, float]:\n    counts = np.bincount(y, minlength=len(CLASS_LABELS))\n    total = float(len(y))\n    weights = {cls: total / (len(CLASS_LABELS) * count) for cls, count in enumerate(counts) if count > 0}\n    return weights\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:42.448820Z","iopub.execute_input":"2025-11-20T05:17:42.449211Z","iopub.status.idle":"2025-11-20T05:17:42.466417Z","shell.execute_reply.started":"2025-11-20T05:17:42.449185Z","shell.execute_reply":"2025-11-20T05:17:42.465211Z"},"papermill":{"duration":0.017878,"end_time":"2025-10-27T06:12:23.399496","exception":false,"start_time":"2025-10-27T06:12:23.381618","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"## Baseline Model Builders","metadata":{"papermill":{"duration":0.007226,"end_time":"2025-10-27T06:12:23.414669","exception":false,"start_time":"2025-10-27T06:12:23.407443","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Performance Dense Baseline","metadata":{"papermill":{"duration":0.007448,"end_time":"2025-10-27T06:12:23.429455","exception":false,"start_time":"2025-10-27T06:12:23.422007","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def build_performance_model(input_dim: int) -> keras.Model:\n    inputs = keras.Input(shape=(input_dim,), name=\"performance_features\")\n    x = keras.layers.Dense(64, activation=\"relu\")(inputs)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Dropout(0.25)(x)\n    x = keras.layers.Dense(32, activation=\"relu\")(x)\n    x = keras.layers.Dropout(0.15)(x)\n    outputs = keras.layers.Dense(len(CLASS_LABELS), activation=\"softmax\")(x)\n    model = keras.Model(inputs, outputs, name=\"performance_dense\")\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n        loss=keras.losses.SparseCategoricalCrossentropy(),\n        metrics=[\"accuracy\"],\n    )\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:42.467446Z","iopub.execute_input":"2025-11-20T05:17:42.468100Z","iopub.status.idle":"2025-11-20T05:17:42.493872Z","shell.execute_reply.started":"2025-11-20T05:17:42.468069Z","shell.execute_reply":"2025-11-20T05:17:42.492708Z"},"papermill":{"duration":0.016135,"end_time":"2025-10-27T06:12:23.453001","exception":false,"start_time":"2025-10-27T06:12:23.436866","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"### Momentum Interaction Baseline","metadata":{"papermill":{"duration":0.007458,"end_time":"2025-10-27T06:12:23.468342","exception":false,"start_time":"2025-10-27T06:12:23.460884","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def build_policy_network(input_dim: int, hidden_units: list[int]) -> keras.Model:\n    inputs = keras.Input(shape=(input_dim,), name=\"policy_state\")\n    x = inputs\n    for units in hidden_units:\n        x = keras.layers.Dense(units, activation=\"relu\")(x)\n        x = keras.layers.LayerNormalization()(x)\n        x = keras.layers.Dropout(0.2)(x)\n    outputs = keras.layers.Dense(len(CLASS_LABELS), activation=\"softmax\")(x)\n    return keras.Model(inputs, outputs, name=\"momentum_policy\")\n\n\ndef discount_returns(rewards: tf.Tensor, gamma: float) -> tf.Tensor:\n    rewards_np = rewards.numpy() if isinstance(rewards, tf.Tensor) else np.asarray(rewards, dtype=np.float32)\n    discounted = np.zeros_like(rewards_np, dtype=np.float32)\n    running = 0.0\n    for t in range(len(rewards_np) - 1, -1, -1):\n        running = rewards_np[t] + gamma * running\n        discounted[t] = running\n    if discounted.std() > 1e-6:\n        discounted = (discounted - discounted.mean()) / (discounted.std() + 1e-6)\n    else:\n        discounted = discounted - discounted.mean()\n    return tf.convert_to_tensor(discounted, dtype=tf.float32)\n\n\nclass PolicyGradientAgent:\n    \"\"\"Simple REINFORCE agent for sequential match prediction with reward shaping.\"\"\"\n\n    def __init__(\n        self,\n        input_dim: int,\n        *,\n        hidden_units: list[int],\n        learning_rate: float,\n        gamma: float,\n        reward_config: dict[str, float] | None = None,\n    ) -> None:\n        self.model = build_policy_network(input_dim, hidden_units)\n        self.optimizer = keras.optimizers.Adam(learning_rate)\n        self.gamma = gamma\n        self.reward_config = {\n            \"draw_correct_bonus\": 0.75,\n            \"market_upset_bonus\": 0.8,\n            \"market_underdog_threshold\": 0.35,\n        }\n        if reward_config is not None:\n            self.reward_config.update(reward_config)\n        self.draw_index = CLASS_LABELS.index(\"Draw\")\n\n    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n        return self.model.predict(X, verbose=0)\n\n    def _compute_step_rewards(\n        self,\n        sampled_actions: tf.Tensor,\n        actions_tf: tf.Tensor,\n        market_probs: tf.Tensor | None,\n    ) -> tf.Tensor:\n        correct_mask = tf.equal(sampled_actions, actions_tf)\n        reward = tf.cast(correct_mask, tf.float32)\n\n        draw_bonus = float(self.reward_config.get(\"draw_correct_bonus\", 0.0))\n        if draw_bonus:\n            draw_idx = tf.constant(self.draw_index, dtype=sampled_actions.dtype)\n            draw_correct_mask = tf.logical_and(correct_mask, tf.equal(sampled_actions, draw_idx))\n            reward += tf.cast(draw_correct_mask, tf.float32) * draw_bonus\n\n        market_bonus = float(self.reward_config.get(\"market_upset_bonus\", 0.0))\n        market_threshold = float(self.reward_config.get(\"market_underdog_threshold\", 0.35))\n        if market_probs is not None and market_bonus:\n            batch_indices = tf.range(tf.shape(sampled_actions)[0], dtype=sampled_actions.dtype)\n            gather_idx = tf.stack([batch_indices, sampled_actions], axis=1)\n            implied_probs = tf.gather_nd(market_probs, gather_idx)\n            threshold = tf.constant(max(market_threshold, 1e-6), dtype=tf.float32)\n            prob_gap = tf.nn.relu(threshold - implied_probs)\n            normalized_gap = tf.math.divide_no_nan(prob_gap, threshold)\n            upset_bonus = tf.cast(correct_mask, tf.float32) * normalized_gap * market_bonus\n            reward += upset_bonus\n\n        return reward\n\n    def train(\n        self,\n        train_episodes: list[dict[str, np.ndarray | None]],\n        val_data: tuple[np.ndarray, np.ndarray],\n        *,\n        epochs: int,\n        eval_interval: int = 1,\n        progress_desc: str | None = None,\n    ) -> dict[str, list[float]]:\n        history = {\"policy_loss\": [], \"avg_reward\": [], \"val_accuracy\": []}\n        X_val, y_val = val_data\n        best_weights = [np.copy(w) for w in self.model.get_weights()]\n        best_val_acc = -np.inf\n\n        progress = tqdm(range(epochs), desc=progress_desc or \"Policy training\", leave=False)\n        for epoch in progress:\n            batch_losses = []\n            batch_rewards = []\n            for episode in train_episodes:\n                states = episode[\"states\"]\n                actions = episode[\"actions\"]\n                market_probs = episode.get(\"market_probs\")\n\n                states_tf = tf.convert_to_tensor(states, dtype=tf.float32)\n                actions_tf = tf.convert_to_tensor(actions, dtype=tf.int32)\n                market_probs_tf = (\n                    tf.convert_to_tensor(market_probs, dtype=tf.float32)\n                    if market_probs is not None\n                    else None\n                )\n\n                with tf.GradientTape() as tape:\n                    probs = self.model(states_tf, training=True)\n                    sampled_actions = tf.random.categorical(\n                        tf.math.log(probs + 1e-9), num_samples=1, dtype=actions_tf.dtype\n                    )\n                    sampled_actions = tf.squeeze(sampled_actions, axis=1)\n                    batch_indices = tf.range(tf.shape(sampled_actions)[0], dtype=sampled_actions.dtype)\n                    gather_idx = tf.stack([batch_indices, sampled_actions], axis=1)\n                    chosen_probs = tf.gather_nd(probs, gather_idx)\n                    rewards = self._compute_step_rewards(sampled_actions, actions_tf, market_probs_tf)\n                    returns = discount_returns(rewards, self.gamma)\n                    loss = -tf.reduce_mean(tf.math.log(chosen_probs + 1e-9) * returns)\n                grads = tape.gradient(loss, self.model.trainable_variables)\n                self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n                batch_losses.append(float(loss.numpy()))\n                batch_rewards.append(float(tf.reduce_mean(rewards).numpy()))\n\n            history[\"policy_loss\"].append(float(np.mean(batch_losses)))\n            history[\"avg_reward\"].append(float(np.mean(batch_rewards)))\n\n            if (epoch + 1) % eval_interval == 0:\n                val_probs = self.predict_proba(X_val)\n                val_preds = np.argmax(val_probs, axis=1)\n                val_acc = float(np.mean(val_preds == y_val))\n                history[\"val_accuracy\"].append(val_acc)\n                progress.set_postfix({\"val_acc\": f\"{val_acc:.3f}\", \"loss\": f\"{history['policy_loss'][-1]:.3f}\"})\n                if val_acc > best_val_acc:\n                    best_val_acc = val_acc\n                    best_weights = [np.copy(w) for w in self.model.get_weights()]\n\n        if best_weights is not None:\n            self.model.set_weights(best_weights)\n        progress.close()\n\n        return history\n\n    def save(self, path: Path) -> None:\n        self.model.save(path, include_optimizer=False)\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:42.494943Z","iopub.execute_input":"2025-11-20T05:17:42.495196Z","iopub.status.idle":"2025-11-20T05:17:42.525304Z","shell.execute_reply.started":"2025-11-20T05:17:42.495176Z","shell.execute_reply":"2025-11-20T05:17:42.524021Z"},"papermill":{"duration":0.028745,"end_time":"2025-10-27T06:12:23.504476","exception":false,"start_time":"2025-10-27T06:12:23.475731","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"### Forecast Calibrator Baseline","metadata":{"papermill":{"duration":0.007282,"end_time":"2025-10-27T06:12:23.519341","exception":false,"start_time":"2025-10-27T06:12:23.512059","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def build_episodes(df: pd.DataFrame, feature_cols: list[str], indices: pd.Index, *, include_market_probs: bool = False) -> list[dict[str, np.ndarray]]:\n    base_cols = [\"season\", \"match_date\", \"target\"]\n    market_cols = MARKET_PROBABILITY_COLUMNS if include_market_probs else []\n    subset_cols = unique(base_cols + feature_cols + market_cols)\n    subset = (\n        df.loc[indices, subset_cols]\n        .sort_values([\"season\", \"match_date\"])\n        .reset_index(drop=True)\n    )\n    episodes: list[dict[str, np.ndarray]] = []\n    for _, season_df in subset.groupby(\"season\", sort=False):\n        episode = {\n            \"states\": season_df[feature_cols].astype(np.float32).to_numpy(),\n            \"actions\": season_df[\"target\"].astype(np.int32).to_numpy(),\n        }\n        if include_market_probs:\n            episode[\"market_probs\"] = season_df[MARKET_PROBABILITY_COLUMNS].astype(np.float32).to_numpy()\n        episodes.append(episode)\n    return episodes\n\n\ndef compute_metrics(y_true: np.ndarray, probs: np.ndarray) -> tuple[float, float, np.ndarray]:\n    preds = np.argmax(probs, axis=1)\n    accuracy = float(np.mean(preds == y_true))\n    clipped = np.clip(probs, 1e-8, 1.0 - 1e-8)\n    logloss = float(-np.mean(np.log(clipped[np.arange(len(y_true)), y_true])))\n    return accuracy, logloss, preds\n\n\ndef save_confusion_heatmap(cm: np.ndarray, labels: list[str], path: Path, title: str) -> None:\n    fig, ax = plt.subplots(figsize=(4, 4))\n    im = ax.imshow(cm, cmap=\"Blues\")\n    ax.set_xticks(range(len(labels)))\n    ax.set_yticks(range(len(labels)))\n    ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n    ax.set_yticklabels(labels)\n    for i in range(len(labels)):\n        for j in range(len(labels)):\n            ax.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n    ax.set_xlabel(\"Predicted\")\n    ax.set_ylabel(\"Actual\")\n    ax.set_title(title)\n    fig.colorbar(im, ax=ax)\n    fig.tight_layout()\n    fig.savefig(path, dpi=160)\n    plt.close(fig)\n\n\ndef to_serializable(obj):\n    if isinstance(obj, dict):\n        return {k: to_serializable(v) for k, v in obj.items()}\n    if isinstance(obj, list):\n        return [to_serializable(v) for v in obj]\n    if isinstance(obj, (np.floating, np.integer)):\n        return obj.item()\n    return obj\n\n\nclass TQDMKerasCallback(keras.callbacks.Callback):\n    \"\"\"Lightweight tqdm progress bar for Keras epoch loops.\"\"\"\n\n    def __init__(self, total_epochs: int, desc: str) -> None:\n        super().__init__()\n        self.total_epochs = total_epochs\n        self.desc = desc\n        self.tqdm_bar = None\n\n    def on_train_begin(self, logs=None):\n        self.tqdm_bar = tqdm(total=self.total_epochs, leave=False)\n        self.tqdm_bar.set_description(self.desc)\n\n    def on_epoch_end(self, epoch, logs=None):\n        if self.tqdm_bar is not None:\n            self.tqdm_bar.update(1)\n            if logs and \"val_accuracy\" in logs:\n                self.tqdm_bar.set_postfix({\"val_acc\": f\"{logs['val_accuracy']:.3f}\", \"loss\": f\"{logs.get('loss', 0.0):.3f}\"})\n\n    def on_train_end(self, logs=None):\n        if self.tqdm_bar is not None:\n            self.tqdm_bar.close()\n            self.tqdm_bar = None\n\n\ndef load_run_log(path: Path, expected_columns: list[str] | None = None) -> pd.DataFrame:\n    columns_seed = expected_columns or RUN_LOG_COLUMNS\n    canonical_columns = list(dict.fromkeys([\"timestamp\", *columns_seed, \"dataset_label\"]))\n    if not path.exists():\n        return pd.DataFrame(columns=canonical_columns)\n    try:\n        df = pd.read_csv(path)\n    except pd.errors.ParserError:\n        df = pd.read_csv(path, engine=\"python\", on_bad_lines=\"skip\")\n    for col in canonical_columns:\n        if col not in df.columns:\n            df[col] = pd.NA\n    df = df.reindex(columns=canonical_columns)\n    df[\"dataset_label\"] = df[\"dataset_label\"].fillna(\"\").astype(str)\n    if \"timestamp\" in df.columns:\n        timestamp_series = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n        missing_mask = timestamp_series.isna()\n        if missing_mask.any():\n            fallback_values = []\n            for run_id in df.loc[missing_mask, \"run_id\"]:\n                ts_value = pd.NaT\n                if isinstance(run_id, str) and run_id:\n                    run_dir = EXPERIMENT_ROOT / f\"run_{run_id}\"\n                    if run_dir.exists():\n                        ts_value = pd.to_datetime(run_dir.stat().st_mtime, unit=\"s\")\n                fallback_values.append(ts_value)\n            timestamp_series.loc[missing_mask] = fallback_values\n        df[\"timestamp\"] = timestamp_series\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:42.526543Z","iopub.execute_input":"2025-11-20T05:17:42.527374Z","iopub.status.idle":"2025-11-20T05:17:42.555523Z","shell.execute_reply.started":"2025-11-20T05:17:42.527340Z","shell.execute_reply":"2025-11-20T05:17:42.554337Z"},"papermill":{"duration":0.026143,"end_time":"2025-10-27T06:12:23.553097","exception":false,"start_time":"2025-10-27T06:12:23.526954","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"### Baseline Registry","metadata":{"papermill":{"duration":0.007213,"end_time":"2025-10-27T06:12:23.567923","exception":false,"start_time":"2025-10-27T06:12:23.56071","status":"completed"},"tags":[]}},{"cell_type":"code","source":"BASELINE_NAMES = list(FEATURE_SETS.keys())\nprint(\"Baselines configured:\", BASELINE_NAMES)\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:42.556697Z","iopub.execute_input":"2025-11-20T05:17:42.557150Z","iopub.status.idle":"2025-11-20T05:17:42.582399Z","shell.execute_reply.started":"2025-11-20T05:17:42.557121Z","shell.execute_reply":"2025-11-20T05:17:42.581111Z"},"papermill":{"duration":0.015526,"end_time":"2025-10-27T06:12:23.590912","exception":false,"start_time":"2025-10-27T06:12:23.575386","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Baselines configured: ['performance_dense', 'momentum_policy_rl', 'market_gradient_boost']\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"## Training and Run Logging","metadata":{"papermill":{"duration":0.00748,"end_time":"2025-10-27T06:12:23.60603","exception":false,"start_time":"2025-10-27T06:12:23.59855","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Training loop with experiment logging\nsce = keras.losses.SparseCategoricalCrossentropy()\n\nbaseline_results = []\nrun_log_entries = []\n\nbaseline_items = list(FEATURE_SETS.items())\n\nfor baseline_name, spec in tqdm(baseline_items, desc=\"Baselines\", leave=False):\n    trainer = spec.get(\"trainer\", \"keras\")\n    feature_cols = spec[\"feature_cols\"]\n    print(f\"Training baseline: {baseline_name} ({trainer})\")\n\n    include_market_probs = spec.get(\"include_market_probs\", False)\n    view_df = prepare_view_frame(sorted_df, feature_cols, include_market_probs=include_market_probs)\n\n    X_train, X_val, X_test = prepare_feature_matrices(\n        view_df,\n        feature_cols,\n        split_indices,\n        scale_strategy=spec.get(\"scale_strategy\"),\n    )\n    y_train = view_df.loc[split_indices[\"train\"], \"target\"].astype(np.int32).to_numpy()\n    y_val = view_df.loc[split_indices[\"val\"], \"target\"].astype(np.int32).to_numpy()\n    y_test = view_df.loc[split_indices[\"test\"], \"target\"].astype(np.int32).to_numpy()\n\n    baseline_dir = MODEL_ARTIFACT_DIR / baseline_name\n    baseline_dir.mkdir(parents=True, exist_ok=True)\n\n    history_dict: dict[str, list] = {}\n    epochs_trained = 0\n    class_weights = None\n\n    if trainer == \"keras\":\n        builder_name = spec.get(\"builder_name\")\n        if builder_name is None:\n            raise ValueError(f\"No builder_name provided for {baseline_name}\")\n        builder = globals()[builder_name]\n\n        train_ds = make_dataset(X_train, y_train, training=True)\n        val_ds = make_dataset(X_val, y_val, training=False)\n        test_ds = make_dataset(X_test, y_test, training=False)\n        train_eval_ds = make_dataset(X_train, y_train, training=False)\n\n        class_weights = compute_class_weights(y_train)\n\n        callbacks = [\n            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True),\n            keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5),\n            TQDMKerasCallback(EPOCHS, f\"{baseline_name} epochs\"),\n        ]\n\n        model = builder(len(feature_cols))\n        history = model.fit(\n            train_ds,\n            validation_data=val_ds,\n            epochs=EPOCHS,\n            callbacks=callbacks,\n            class_weight=class_weights,\n            verbose=0,\n        )\n        history_dict = history.history\n        epochs_trained = len(history_dict.get(\"loss\", []))\n\n        train_probs = model.predict(train_eval_ds, verbose=0)\n        val_probs = model.predict(val_ds, verbose=0)\n        test_probs = model.predict(test_ds, verbose=0)\n\n        model.save(baseline_dir / \"model.keras\", include_optimizer=False)\n\n    elif trainer == \"reinforce\":\n        input_dim = X_train.shape[1]\n        train_episodes = build_episodes(view_df, feature_cols, split_indices[\"train\"], include_market_probs=include_market_probs)\n        agent = PolicyGradientAgent(\n            input_dim,\n            hidden_units=spec.get(\"policy_hidden_units\", [128, 64]),\n            learning_rate=spec.get(\"learning_rate\", 5e-4),\n            gamma=spec.get(\"gamma\", 0.95),\n            reward_config=spec.get(\"reward_config\"),\n        )\n        policy_epochs = spec.get(\"policy_epochs\", max(EPOCHS, 60))\n        history_dict = agent.train(\n            train_episodes,\n            val_data=(X_val, y_val),\n            epochs=policy_epochs,\n            eval_interval=spec.get(\"eval_interval\", 1),\n            progress_desc=f\"{baseline_name} policy\",\n        )\n        epochs_trained = len(history_dict.get(\"policy_loss\", []))\n\n        train_probs = agent.predict_proba(X_train)\n        val_probs = agent.predict_proba(X_val)\n        test_probs = agent.predict_proba(X_test)\n\n        agent.save(baseline_dir / \"model.keras\")\n\n    elif trainer == \"xgboost\":\n        params = spec.get(\"xgb_params\", {}).copy()\n        eval_metric = params.pop(\"eval_metric\", \"mlogloss\")\n        model = xgb.XGBClassifier(eval_metric=eval_metric, **params)\n        model.fit(\n            X_train,\n            y_train,\n            eval_set=[(X_val, y_val)],\n            verbose=False,\n            early_stopping_rounds=40,\n        )\n        history_dict = model.evals_result()\n        if hasattr(model, \"best_iteration\") and model.best_iteration is not None:\n            epochs_trained = int(model.best_iteration) + 1\n        else:\n            epochs_trained = int(model.n_estimators)\n\n        train_probs = model.predict_proba(X_train)\n        val_probs = model.predict_proba(X_val)\n        test_probs = model.predict_proba(X_test)\n\n        model.save_model(str(baseline_dir / \"model.json\"))\n\n    else:\n        raise ValueError(f\"Unknown trainer type: {trainer}\")\n\n    train_accuracy, train_logloss, train_preds = compute_metrics(y_train, train_probs)\n    val_accuracy, val_logloss, val_preds = compute_metrics(y_val, val_probs)\n    test_accuracy, test_logloss, test_preds = compute_metrics(y_test, test_probs)\n\n    confusion = tf.math.confusion_matrix(y_test, test_preds, num_classes=len(CLASS_LABELS)).numpy()\n    save_confusion_heatmap(confusion, CLASS_LABELS, baseline_dir / \"confusion_matrix.png\", f\"{baseline_name} — Test Confusion\")\n\n    eval_rows = sorted_df.loc[split_indices[\"test\"], [\n        \"match_id\",\n        \"season\",\n        \"match_date\",\n        \"home_team\",\n        \"away_team\",\n        \"target\",\n    ]].copy()\n    eval_rows[\"predicted\"] = test_preds\n    eval_rows[\"predicted_label\"] = eval_rows[\"predicted\"].map(dict(enumerate(CLASS_LABELS)))\n    eval_rows[\"target_label\"] = eval_rows[\"target\"].map(dict(enumerate(CLASS_LABELS)))\n    eval_rows[\"home_prob\"] = test_probs[:, 0]\n    eval_rows[\"draw_prob\"] = test_probs[:, 1]\n    eval_rows[\"away_prob\"] = test_probs[:, 2]\n    eval_rows.to_csv(baseline_dir / \"test_predictions.csv\", index=False)\n\n    with open(baseline_dir / \"history.json\", \"w\") as fp:\n        json.dump(to_serializable(history_dict), fp, indent=2)\n\n    metrics_payload = {\n        \"trainer\": trainer,\n        \"train\": {\"accuracy\": train_accuracy, \"logloss\": train_logloss},\n        \"val\": {\"accuracy\": val_accuracy, \"logloss\": val_logloss},\n        \"test\": {\"accuracy\": test_accuracy, \"logloss\": test_logloss},\n        \"epochs_trained\": epochs_trained,\n        \"feature_cols\": feature_cols,\n        \"dataset_label\": DATASET_LABEL,\n    }\n    if class_weights is not None:\n        metrics_payload[\"class_weights\"] = class_weights\n\n    with open(baseline_dir / \"metrics.json\", \"w\") as fp:\n        json.dump(to_serializable(metrics_payload), fp, indent=2)\n\n    baseline_results.append({\n        \"baseline\": baseline_name,\n        \"trainer\": trainer,\n        \"description\": spec[\"description\"],\n        \"val_accuracy\": val_accuracy,\n        \"test_accuracy\": test_accuracy,\n        \"val_logloss\": val_logloss,\n        \"test_logloss\": test_logloss,\n        \"epochs\": epochs_trained,\n        \"dataset_label\": DATASET_LABEL,\n    })\n\n    run_log_entries.append({\n        \"timestamp\": datetime.utcnow().isoformat(),\n        \"run_id\": RUN_ID,\n        \"baseline\": baseline_name,\n        \"trainer\": trainer,\n        \"feature_view\": spec[\"description\"],\n        \"train_accuracy\": train_accuracy,\n        \"val_accuracy\": val_accuracy,\n        \"test_accuracy\": test_accuracy,\n        \"train_loss\": train_logloss,\n        \"val_loss\": val_logloss,\n        \"test_loss\": test_logloss,\n        \"val_logloss\": val_logloss,\n        \"test_logloss\": test_logloss,\n        \"epochs_trained\": epochs_trained,\n        \"seasons\": \"|\".join(SEASONS),\n        \"dataset_label\": DATASET_LABEL or \"\",\n        \"notes\": \"\",\n    })\n\nbaseline_summary_df = pd.DataFrame(baseline_results).sort_values(\"val_accuracy\", ascending=False)\ndisplay(baseline_summary_df)\n\nif run_log_entries:\n    run_log_df = pd.DataFrame(run_log_entries)\n    run_log_df[\"timestamp\"] = [\n        entry.get(\"timestamp\") or datetime.utcnow().isoformat()\n        for entry in run_log_entries\n    ]\n    canonical_columns = list(dict.fromkeys([\"timestamp\", *RUN_LOG_COLUMNS, *run_log_df.columns.tolist(), \"dataset_label\"]))\n    run_log_df = run_log_df.reindex(columns=canonical_columns)\n    existing_log_df = load_run_log(RUN_LOG_PATH, expected_columns=canonical_columns)\n    combined_log_df = pd.concat([existing_log_df, run_log_df], ignore_index=True)\n    combined_log_df = combined_log_df.reindex(columns=canonical_columns)\n    combined_log_df[\"timestamp\"] = combined_log_df[\"timestamp\"].apply(\n        lambda ts: (\n            \"\" if pd.isna(ts)\n            else ts.isoformat() if isinstance(ts, (pd.Timestamp, datetime))\n            else str(ts)\n        )\n    )\n    combined_log_df.to_csv(RUN_LOG_PATH, index=False)\n    display(run_log_df[[\"baseline\", \"trainer\", \"dataset_label\", \"val_accuracy\", \"test_accuracy\", \"epochs_trained\"]])\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:17:42.583847Z","iopub.execute_input":"2025-11-20T05:17:42.584208Z","iopub.status.idle":"2025-11-20T05:18:06.356370Z","shell.execute_reply.started":"2025-11-20T05:17:42.584185Z","shell.execute_reply":"2025-11-20T05:18:06.355179Z"},"papermill":{"duration":22.592161,"end_time":"2025-10-27T06:12:46.205639","exception":false,"start_time":"2025-10-27T06:12:23.613478","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Baselines:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training baseline: performance_dense (keras)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d4a0cc5bc8344ee889c47e1729b1988"}},"metadata":{}},{"name":"stdout","text":"Training baseline: momentum_policy_rl (reinforce)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"momentum_policy_rl policy:   0%|          | 0/60 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training baseline: market_gradient_boost (xgboost)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                baseline    trainer  \\\n0      performance_dense      keras   \n2  market_gradient_boost    xgboost   \n1     momentum_policy_rl  reinforce   \n\n                                         description  val_accuracy  \\\n0  Performance-based dense network using smoothed...      0.583333   \n2                     Market odds derived statistics      0.574561   \n1  Momentum-policy REINFORCE agent leveraging sho...      0.517544   \n\n   test_accuracy  val_logloss  test_logloss  epochs dataset_label  \n0       0.574561     0.922981      0.894500      28            V3  \n2       0.557018     0.892678      0.875061      48            V3  \n1       0.526316     1.588921      1.445900      60            V3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>baseline</th>\n      <th>trainer</th>\n      <th>description</th>\n      <th>val_accuracy</th>\n      <th>test_accuracy</th>\n      <th>val_logloss</th>\n      <th>test_logloss</th>\n      <th>epochs</th>\n      <th>dataset_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>performance_dense</td>\n      <td>keras</td>\n      <td>Performance-based dense network using smoothed...</td>\n      <td>0.583333</td>\n      <td>0.574561</td>\n      <td>0.922981</td>\n      <td>0.894500</td>\n      <td>28</td>\n      <td>V3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>market_gradient_boost</td>\n      <td>xgboost</td>\n      <td>Market odds derived statistics</td>\n      <td>0.574561</td>\n      <td>0.557018</td>\n      <td>0.892678</td>\n      <td>0.875061</td>\n      <td>48</td>\n      <td>V3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>momentum_policy_rl</td>\n      <td>reinforce</td>\n      <td>Momentum-policy REINFORCE agent leveraging sho...</td>\n      <td>0.517544</td>\n      <td>0.526316</td>\n      <td>1.588921</td>\n      <td>1.445900</td>\n      <td>60</td>\n      <td>V3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                baseline    trainer dataset_label  val_accuracy  \\\n0      performance_dense      keras            V3      0.583333   \n1     momentum_policy_rl  reinforce            V3      0.517544   \n2  market_gradient_boost    xgboost            V3      0.574561   \n\n   test_accuracy  epochs_trained  \n0       0.574561              28  \n1       0.526316              60  \n2       0.557018              48  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>baseline</th>\n      <th>trainer</th>\n      <th>dataset_label</th>\n      <th>val_accuracy</th>\n      <th>test_accuracy</th>\n      <th>epochs_trained</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>performance_dense</td>\n      <td>keras</td>\n      <td>V3</td>\n      <td>0.583333</td>\n      <td>0.574561</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>momentum_policy_rl</td>\n      <td>reinforce</td>\n      <td>V3</td>\n      <td>0.517544</td>\n      <td>0.526316</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>market_gradient_boost</td>\n      <td>xgboost</td>\n      <td>V3</td>\n      <td>0.574561</td>\n      <td>0.557018</td>\n      <td>48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":"## Historical Comparison","metadata":{"papermill":{"duration":0.008605,"end_time":"2025-10-27T06:12:46.223491","exception":false,"start_time":"2025-10-27T06:12:46.214886","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run history synchronisation\nfrom analysis.sync_run_history import sync_run_history\n\nhistory_sync_summary = sync_run_history(\n    EXPERIMENT_ROOT,\n    RUN_LOG_PATH,\n    baseline_descriptions={name: spec.get('description', name) for name, spec in FEATURE_SETS.items()},\n    canonical_columns=RUN_LOG_COLUMNS,\n)\nprint(\n    \"Run history synced — \"\n    f\"{history_sync_summary['created']} new entries, \"\n    f\"{history_sync_summary['updated']} updated, \"\n    f\"{history_sync_summary['total']} total rows.\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T05:18:06.359788Z","iopub.execute_input":"2025-11-20T05:18:06.360221Z","iopub.status.idle":"2025-11-20T05:18:06.383631Z","shell.execute_reply.started":"2025-11-20T05:18:06.360197Z","shell.execute_reply":"2025-11-20T05:18:06.381837Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/665485193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run history synchronisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_run_history\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msync_run_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m history_sync_summary = sync_run_history(\n\u001b[1;32m      5\u001b[0m     \u001b[0mEXPERIMENT_ROOT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'analysis'"],"ename":"ModuleNotFoundError","evalue":"No module named 'analysis'","output_type":"error"}],"execution_count":52},{"cell_type":"code","source":"# Historical comparison versus prior runs\nif RUN_LOG_PATH.exists():\n    history_df = load_run_log(RUN_LOG_PATH)\n    existing_run_ids = {\n        p.name.replace(\"run_\", \"\")\n        for p in EXPERIMENT_ROOT.glob(\"run_*\")\n        if p.is_dir()\n    }\n    if existing_run_ids:\n        history_df = history_df[history_df[\"run_id\"].isin(existing_run_ids)].copy()\n    else:\n        history_df = history_df.iloc[0:0]\n    history_df[\"timestamp\"] = pd.to_datetime(history_df[\"timestamp\"], errors=\"coerce\")\n    history_df.sort_values(\"timestamp\", inplace=True)\n\n    if history_df.empty:\n        print(\"No completed runs with artefacts found. Generate a new run and rerun this cell.\")\n    else:\n        unlabeled_mask = history_df[\"dataset_label\"].astype(str).str.strip() == \"\"\n        unlabeled_df = history_df[unlabeled_mask]\n\n        if not unlabeled_df.empty:\n            print(\"Some historical runs are missing dataset labels. Provide a label for each data point below and click 'Apply labels', then rerun this cell to render the chart.\")\n            label_inputs = {}\n            widgets_list = []\n            for row_index, row in unlabeled_df.iterrows():\n                default_value = DATASET_LABEL or \"\"\n                descriptor = f\"{row['baseline']} — {row['run_id']}\"\n                text_widget = widgets.Text(\n                    value=default_value,\n                    description=descriptor,\n                    placeholder=\"Enter dataset name\",\n                    layout=widgets.Layout(width=\"70%\"),\n                )\n                label_inputs[row_index] = text_widget\n                widgets_list.append(text_widget)\n\n            apply_button = widgets.Button(description=\"Apply labels\", button_style=\"primary\")\n            status_html = widgets.HTML()\n\n            def _apply_labels(_):\n                for row_index, widget_box in label_inputs.items():\n                    history_df.at[row_index, \"dataset_label\"] = widget_box.value.strip()\n                history_df[RUN_LOG_COLUMNS].to_csv(RUN_LOG_PATH, index=False)\n                status_html.value = \"<span style='color:green;'>Dataset labels saved. Rerun this cell to update the comparison chart.</span>\"\n\n            apply_button.on_click(_apply_labels)\n            display(widgets.VBox(widgets_list + [apply_button, status_html]))\n        else:\n            latest_df = history_df[history_df[\"run_id\"] == RUN_ID]\n            best_df = history_df.sort_values(\"val_accuracy\", ascending=False).drop_duplicates(\"baseline\")\n            comparison = latest_df.merge(\n                best_df[[\"baseline\", \"val_accuracy\", \"test_accuracy\", \"run_id\", \"dataset_label\"]],\n                on=\"baseline\",\n                suffixes=(\"_current\", \"_best\"),\n            )\n\n            print(\"Most recent run vs historical best (by validation accuracy):\")\n            if not comparison.empty:\n                display(comparison[[\n                    \"baseline\",\n                    \"dataset_label_current\",\n                    \"dataset_label_best\",\n                    \"val_accuracy_current\",\n                    \"val_accuracy_best\",\n                    \"test_accuracy_current\",\n                    \"test_accuracy_best\",\n                    \"run_id_best\",\n                ]])\n            else:\n                print(\"No runs for the current run ID yet.\")\n\n            fig, ax = plt.subplots(figsize=(10, 5))\n            for baseline in history_df[\"baseline\"].unique():\n                subset = history_df[history_df[\"baseline\"] == baseline].dropna(subset=[\"timestamp\"])\n                if subset.empty:\n                    continue\n                ax.plot(subset[\"timestamp\"], subset[\"val_accuracy\"], marker=\"o\", label=baseline)\n                for row in subset.itertuples():\n                    label_text = getattr(row, \"dataset_label\", \"\").strip()\n                    if label_text:\n                        ax.annotate(\n                            label_text,\n                            (row.timestamp, row.val_accuracy),\n                            textcoords=\"offset points\",\n                            xytext=(0, 6),\n                            ha=\"center\",\n                            fontsize=8,\n                            color=\"dimgray\",\n                        )\n            ax.set_title(\"Validation accuracy trajectory by baseline\")\n            ax.set_ylabel(\"Validation accuracy\")\n            ax.set_xlabel(\"Run timestamp\")\n            ax.grid(True, alpha=0.3)\n            ax.legend()\n            fig.autofmt_xdate()\n            fig.tight_layout()\n            plot_path = MODEL_ARTIFACT_DIR / \"validation_accuracy_history.png\"\n            fig.savefig(plot_path, dpi=160)\n            plt.show()\n            print(f\"Saved validation accuracy history plot to {plot_path}\")\nelse:\n    print(\"Run history file not found — this will be created after the first successful training run.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:18:06.384881Z","iopub.status.idle":"2025-11-20T05:18:06.385233Z","shell.execute_reply.started":"2025-11-20T05:18:06.385086Z","shell.execute_reply":"2025-11-20T05:18:06.385100Z"},"papermill":{"duration":0.051159,"end_time":"2025-10-27T06:12:46.283095","exception":false,"start_time":"2025-10-27T06:12:46.231936","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Confusion Matrices for each Model\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom pathlib import Path\n\ndef resolve_run_dir() -> Path:\n    if \"MODEL_ARTIFACT_DIR\" in globals() and MODEL_ARTIFACT_DIR.exists():\n        return MODEL_ARTIFACT_DIR\n    candidates = [p for p in EXPERIMENT_ROOT.glob(\"run_*\") if p.is_dir()]\n    if not candidates:\n        raise FileNotFoundError(\"No experiment runs found under EXPERIMENT_ROOT.\")\n    return max(candidates, key=lambda p: p.stat().st_mtime)\n\nrun_dir = resolve_run_dir()\nnum_classes = len(CLASS_LABELS)\nfig, axes = plt.subplots(1, len(FEATURE_SETS), figsize=(5 * len(FEATURE_SETS), 4), squeeze=False)\n\nfor ax, (baseline_name, spec) in zip(axes.flat, FEATURE_SETS.items()):\n    pred_path = run_dir / baseline_name / \"test_predictions.csv\"\n    if not pred_path.exists():\n        raise FileNotFoundError(f\"Missing predictions at {pred_path}. Run the training cell first.\")\n    eval_df = pd.read_csv(pred_path)\n    cm = tf.math.confusion_matrix(\n        eval_df[\"target\"].to_numpy(),\n        eval_df[\"predicted\"].to_numpy(),\n        num_classes=num_classes\n    ).numpy()\n    im = ax.imshow(cm, cmap=\"Blues\")\n    ax.set_title(spec[\"description\"], fontsize=10)\n    ax.set_xticks(range(num_classes))\n    ax.set_yticks(range(num_classes))\n    ax.set_xticklabels(CLASS_LABELS, rotation=45, ha=\"right\")\n    ax.set_yticklabels(CLASS_LABELS)\n    for i in range(num_classes):\n        for j in range(num_classes):\n            ax.text(j, i, int(cm[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n    ax.set_xlabel(\"Predicted\")\n    ax.set_ylabel(\"Actual\")\n\nfig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.9, label=\"Match count\")\nfig.suptitle(\"Test-set Confusion Matrices by Baseline\", y=1.02)\nfig.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:18:06.386298Z","iopub.status.idle":"2025-11-20T05:18:06.386699Z","shell.execute_reply.started":"2025-11-20T05:18:06.386503Z","shell.execute_reply":"2025-11-20T05:18:06.386522Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## Next Steps\n- Extend feature engineering with financial and odds datasets described in the README, maintaining the logging conventions used here.\n- Layer on attribution analysis (approximate Shapley, LOO) by loading saved `model.keras` files and pairing them with cached train/validation datasets.\n- Use the persisted `baseline_run_history.csv` to drive Kaggle dashboard widgets or automated alerts when new dataset versions shift model behaviour.\n- Use a pretrained model rather than starting from scratch, also look into how this would affect newer dataset versions, how would new features be added?","metadata":{"papermill":{"duration":0.008346,"end_time":"2025-10-27T06:12:46.300145","exception":false,"start_time":"2025-10-27T06:12:46.291799","status":"completed"},"tags":[]}},{"cell_type":"code","source":"##rm -rf experiments/run_20251027-204500","metadata":{"execution":{"iopub.status.busy":"2025-11-20T05:18:06.388971Z","iopub.status.idle":"2025-11-20T05:18:06.389603Z","shell.execute_reply.started":"2025-11-20T05:18:06.389351Z","shell.execute_reply":"2025-11-20T05:18:06.389374Z"},"papermill":{"duration":0.015616,"end_time":"2025-10-27T06:12:46.324339","exception":false,"start_time":"2025-10-27T06:12:46.308723","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}